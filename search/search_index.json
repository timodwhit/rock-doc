{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 Welcome to your Rock Robotic R1a! Package Contents \u00b6 In the box: 1 x Rock Robotic R1a LiDAR 1 x usb stick 1 x Hard case 1 x GNSS Antenna Getting Started \u00b6 Please follow our Quickstart Guide to start collecting data quickly. Collaboration \u00b6 This document can be edited on GitHub in markdown. If you find any mistakes, typos or pieces that are not documented well enough simply open an issue or contribute by sending a pull request. Discussion \u00b6 We are happy to answer any questions at community.rockrobotic.com .","title":"Introduction"},{"location":"#introduction","text":"Welcome to your Rock Robotic R1a!","title":"Introduction"},{"location":"#package-contents","text":"In the box: 1 x Rock Robotic R1a LiDAR 1 x usb stick 1 x Hard case 1 x GNSS Antenna","title":"Package Contents"},{"location":"#getting-started","text":"Please follow our Quickstart Guide to start collecting data quickly.","title":"Getting Started"},{"location":"#collaboration","text":"This document can be edited on GitHub in markdown. If you find any mistakes, typos or pieces that are not documented well enough simply open an issue or contribute by sending a pull request.","title":"Collaboration"},{"location":"#discussion","text":"We are happy to answer any questions at community.rockrobotic.com .","title":"Discussion"},{"location":"Calibration/Calibration/","text":"Calibrating the LiDAR \u00b6 Before each acquisition and at the end of each acquisition the LiDAR system needs to be calibrated. Overview \u00b6 Make Sure Before proceeding to the LiDAR Calibration make certain the base station is setup and logging static RINEX 3.03 measurements Calibrating the LiDAR is an important step to collecting accurate data, and the procedure will be done twice at each acquisition session. One time at the beginning, right after you start the R1A from the WebServer. (See Connecting to R1A WiFi for information oh how to start the R1A from the web interface) and one time at the very end of your acquisition flights. Procedure \u00b6 Start the R1A LiDAR \u00b6 Using the web interface, wait until you have 8 or more GNSS satellites. Then press the start button inside the data recording window. Collect Static Data \u00b6 The R1A needs to get a static alignment. After you start data recording, then let the R1A sit completely still and allow a clear view of the sky and wait 15 seconds. Once the app interface says 'Waiting for high speed kinematic alignment' you can proceed to the next step. Kinematic Alignment \u00b6 Take off and fly directly vertical. For at least 6 seconds fly greater than 5 m/s in a straight line in the forward direction of flight. Fly figure 8 pattern \u00b6 Now fly 2 figure 8 patterns in the sky. Figure 1 Fly your mission \u00b6 Great! Now the LiDAR is calibrated and you can begin flying your mission plan. Either upload the mission while still in the air or land upload and take off again! Calibration Complete Mid-mission Battery Change \u00b6 If your mission will require multiple battery changes, fly directly forward back to the landing zone at a speed greater than 5 m/s . Once you get overhead, do not exceed 2 m/s in horizontal speed while you turn the drone and bring it in for a landing. Keep the drone on the ground for no longer than 5 Minutes while you change the batteries. If you remain on the ground for much longer than 5 minutes you are better off proceeding to the shutdown proceedure . Assuming you take off within the 2 minute window, take off and resume your mission. End of Mission Calibration \u00b6 At the end of your mission, fly directly forward back to the landing zone at a speed greater than 5 m/s . Once you get overhead, do not exceed 2 m/s in horizontal speed while you turn the drone and bring it in for a landing. Once landed don't move the system for 15 seconds. This will capture a final static alignment dataset. Then you can connect via the web interface and stop collecting data. You are Done!","title":"Calibration"},{"location":"Calibration/Calibration/#calibrating-the-lidar","text":"Before each acquisition and at the end of each acquisition the LiDAR system needs to be calibrated.","title":"Calibrating the LiDAR"},{"location":"Calibration/Calibration/#overview","text":"Make Sure Before proceeding to the LiDAR Calibration make certain the base station is setup and logging static RINEX 3.03 measurements Calibrating the LiDAR is an important step to collecting accurate data, and the procedure will be done twice at each acquisition session. One time at the beginning, right after you start the R1A from the WebServer. (See Connecting to R1A WiFi for information oh how to start the R1A from the web interface) and one time at the very end of your acquisition flights.","title":"Overview"},{"location":"Calibration/Calibration/#procedure","text":"","title":"Procedure"},{"location":"Calibration/Calibration/#start-the-r1a-lidar","text":"Using the web interface, wait until you have 8 or more GNSS satellites. Then press the start button inside the data recording window.","title":"Start the R1A LiDAR"},{"location":"Calibration/Calibration/#collect-static-data","text":"The R1A needs to get a static alignment. After you start data recording, then let the R1A sit completely still and allow a clear view of the sky and wait 15 seconds. Once the app interface says 'Waiting for high speed kinematic alignment' you can proceed to the next step.","title":"Collect Static Data"},{"location":"Calibration/Calibration/#kinematic-alignment","text":"Take off and fly directly vertical. For at least 6 seconds fly greater than 5 m/s in a straight line in the forward direction of flight.","title":"Kinematic Alignment"},{"location":"Calibration/Calibration/#fly-figure-8-pattern","text":"Now fly 2 figure 8 patterns in the sky. Figure 1","title":"Fly figure 8 pattern"},{"location":"Calibration/Calibration/#fly-your-mission","text":"Great! Now the LiDAR is calibrated and you can begin flying your mission plan. Either upload the mission while still in the air or land upload and take off again! Calibration Complete","title":"Fly your mission"},{"location":"Calibration/Calibration/#mid-mission-battery-change","text":"If your mission will require multiple battery changes, fly directly forward back to the landing zone at a speed greater than 5 m/s . Once you get overhead, do not exceed 2 m/s in horizontal speed while you turn the drone and bring it in for a landing. Keep the drone on the ground for no longer than 5 Minutes while you change the batteries. If you remain on the ground for much longer than 5 minutes you are better off proceeding to the shutdown proceedure . Assuming you take off within the 2 minute window, take off and resume your mission.","title":"Mid-mission Battery Change"},{"location":"Calibration/Calibration/#end-of-mission-calibration","text":"At the end of your mission, fly directly forward back to the landing zone at a speed greater than 5 m/s . Once you get overhead, do not exceed 2 m/s in horizontal speed while you turn the drone and bring it in for a landing. Once landed don't move the system for 15 seconds. This will capture a final static alignment dataset. Then you can connect via the web interface and stop collecting data. You are Done!","title":"End of Mission Calibration"},{"location":"drone-setup/alta-x/","text":"Freefly Alta-X Setup \u00b6 The ROCK R1A mounts to the Alta X using a 'Toad in the hole' mount (sold separately). The R1A will need a 4 cell LiPO battery to power the system. Antenna \u00b6 Included with the mount is an antenna which uses one of the free holes on top of the drone to be affixed to the drone.","title":"Freefly Alta-X"},{"location":"drone-setup/alta-x/#freefly-alta-x-setup","text":"The ROCK R1A mounts to the Alta X using a 'Toad in the hole' mount (sold separately). The R1A will need a 4 cell LiPO battery to power the system.","title":"Freefly Alta-X Setup"},{"location":"drone-setup/alta-x/#antenna","text":"Included with the mount is an antenna which uses one of the free holes on top of the drone to be affixed to the drone.","title":"Antenna"},{"location":"drone-setup/m200/","text":"DJI Matrice 200 Setup \u00b6 The ROCK R1A connects directly to the DJI Matrice 200 using the vibration dampening Skyport. The R1A will draw power from the system's battery once connected. Antenna \u00b6 The included antenna is to be screwed into one of the screw holes on the top of the drone.","title":"Matrice 200"},{"location":"drone-setup/m200/#dji-matrice-200-setup","text":"The ROCK R1A connects directly to the DJI Matrice 200 using the vibration dampening Skyport. The R1A will draw power from the system's battery once connected.","title":"DJI Matrice 200 Setup"},{"location":"drone-setup/m200/#antenna","text":"The included antenna is to be screwed into one of the screw holes on the top of the drone.","title":"Antenna"},{"location":"drone-setup/m210/","text":"DJI Matrice 210 Setup \u00b6 The ROCK R1A connects directly to the DJI Matrice 210 using the vibration dampening Skyport. The R1A will draw power from the system's battery once connected. Antenna \u00b6 The included antenna is to be screwed into one of the screw holes on the top of the drone.","title":"Matrice 210"},{"location":"drone-setup/m210/#dji-matrice-210-setup","text":"The ROCK R1A connects directly to the DJI Matrice 210 using the vibration dampening Skyport. The R1A will draw power from the system's battery once connected.","title":"DJI Matrice 210 Setup"},{"location":"drone-setup/m210/#antenna","text":"The included antenna is to be screwed into one of the screw holes on the top of the drone.","title":"Antenna"},{"location":"drone-setup/m300/","text":"DJI Matrice 300 Setup \u00b6 The ROCK R1A connects directly to the DJI Matrice 300 using the vibration dampening Skyport. The R1A will draw power from the system's battery once connected. Antenna \u00b6 The included antenna is to be screwed into one of the screw holes on the top of the drone.","title":"Matrice 300 RTK"},{"location":"drone-setup/m300/#dji-matrice-300-setup","text":"The ROCK R1A connects directly to the DJI Matrice 300 using the vibration dampening Skyport. The R1A will draw power from the system's battery once connected.","title":"DJI Matrice 300 Setup"},{"location":"drone-setup/m300/#antenna","text":"The included antenna is to be screwed into one of the screw holes on the top of the drone.","title":"Antenna"},{"location":"drone-setup/m600/","text":"DJI Matrice 600 Setup \u00b6 The ROCK R1A mounts to the M600 using a vibration dampening mount (sold separately). The R1A will need a 4 cell LiPO battery to power the system. Antenna \u00b6 Included with the R1A mount is an antenna bracket which is to be screwed into the top of the M600 using one of the free screw holes.","title":"Matrice 600"},{"location":"drone-setup/m600/#dji-matrice-600-setup","text":"The ROCK R1A mounts to the M600 using a vibration dampening mount (sold separately). The R1A will need a 4 cell LiPO battery to power the system.","title":"DJI Matrice 600 Setup"},{"location":"drone-setup/m600/#antenna","text":"Included with the R1A mount is an antenna bracket which is to be screwed into the top of the M600 using one of the free screw holes.","title":"Antenna"},{"location":"drone-setup/other/","text":"Other Drone Systems \u00b6 The ROCK R1A can be purchased with a universal mount which connects to the drone using the M4 Toad in the Hole by Freefly Systems. The mounting portion which needs to be connected to your drone is the M4 Quick Release Receiver . See specs Antenna \u00b6 Usually one of our existing antenna mounting designs will work for your drone. TBD based on needs.","title":"Other Drone Systems"},{"location":"drone-setup/other/#other-drone-systems","text":"The ROCK R1A can be purchased with a universal mount which connects to the drone using the M4 Toad in the Hole by Freefly Systems. The mounting portion which needs to be connected to your drone is the M4 Quick Release Receiver . See specs","title":"Other Drone Systems"},{"location":"drone-setup/other/#antenna","text":"Usually one of our existing antenna mounting designs will work for your drone. TBD based on needs.","title":"Antenna"},{"location":"mission-planning/mission-planning/","text":"Mission Planning \u00b6 In this section we will provide recommendation for mission planning software. These are 3rd party software and are only from our experience and recommendations. With all mission planning software a certain level of risk exists and you as a pilot must remain aware at all times. Becoming an expert LiDAR mapper requires a good understanding of mission planning. I will get into all the details of the many little things to think about that will increase your efficiency and therefore productivity. But first, the basics. The quality of your LiDAR dataset depends on 3 factors: Flight Height Flight Line width Flight Speed In this section We provide 2 recommended settings that will get you best results. Then for further understanding of complex job site, large area mapping planning, or structure mapping, we recommend you to our detailed tutorial series on mission planning. Recommended Flight Control Software \u00b6","title":"Mission Planning"},{"location":"mission-planning/mission-planning/#mission-planning","text":"In this section we will provide recommendation for mission planning software. These are 3rd party software and are only from our experience and recommendations. With all mission planning software a certain level of risk exists and you as a pilot must remain aware at all times. Becoming an expert LiDAR mapper requires a good understanding of mission planning. I will get into all the details of the many little things to think about that will increase your efficiency and therefore productivity. But first, the basics. The quality of your LiDAR dataset depends on 3 factors: Flight Height Flight Line width Flight Speed In this section We provide 2 recommended settings that will get you best results. Then for further understanding of complex job site, large area mapping planning, or structure mapping, we recommend you to our detailed tutorial series on mission planning.","title":"Mission Planning"},{"location":"mission-planning/mission-planning/#recommended-flight-control-software","text":"","title":"Recommended Flight Control Software"},{"location":"placing-the-base/settingup/","text":"A well-placed Reach base is essential for achieving good RTK positioning results. You can place your smartphone near the window in your house and it will obtain GNSS coordinates after some time, but for the R1A LiDAR such environment won't be sufficient. For the R1A to work there are special requirements for placing the base. Clear sky view without any obstacles \u00b6 The base station needs to have a clear sky view 30 degrees above the horizon. There should be no obstacles that could block the view like buildings, trees, cars, humans, laptops, etc. Take a look at 2 pictures below. The left picture demonstrates desirable conditions for the base location. The right one is an example of bad surrounding conditions such as the reduced view of the sky, possible obstructions or vegetation nearby. Examples of good environments for base placement: field top of the hill rooftop Examples of bad environments for base placement: indoors urban area forestry area No electronics nearby \u00b6 Electronic devices may produce RF noise that could affect the reception of the GNSS signal. Keep all electronics as far as possible from base and R1A. Setting up the base \u00b6 Learn more about placing the base from the dedicated article in our docs.","title":"Placing the Base"},{"location":"placing-the-base/settingup/#clear-sky-view-without-any-obstacles","text":"The base station needs to have a clear sky view 30 degrees above the horizon. There should be no obstacles that could block the view like buildings, trees, cars, humans, laptops, etc. Take a look at 2 pictures below. The left picture demonstrates desirable conditions for the base location. The right one is an example of bad surrounding conditions such as the reduced view of the sky, possible obstructions or vegetation nearby. Examples of good environments for base placement: field top of the hill rooftop Examples of bad environments for base placement: indoors urban area forestry area","title":"Clear sky view without any obstacles"},{"location":"placing-the-base/settingup/#no-electronics-nearby","text":"Electronic devices may produce RF noise that could affect the reception of the GNSS signal. Keep all electronics as far as possible from base and R1A.","title":"No electronics nearby"},{"location":"placing-the-base/settingup/#setting-up-the-base","text":"Learn more about placing the base from the dedicated article in our docs.","title":"Setting up the base"},{"location":"pre-processing/colorizing/","text":"Point Cloud Colorizing \u00b6 Key Features \u00b6 The key features of PCPainterGL are: Fast data processing On the fly point cloud visualization On the fly visualization of misalignment correction Point coloring by digital image overlay XML project format for ease of automation Platform Requirements \u00b6 PCPainterGL works on Windows 10 x64 (MacOS and Linux x64 versions are in development). The key requirement for seamless visualization of large point clouds is a fast GPU with large video memory (dedicated or shared). The software has been tested on nVidia GeForce GTX graphics cards, but it is hardware independent. The rule of thumb is 1 GB of memory for every 15 million points in the cloud. The current software limit is ~800 million points. Fast data processing also requires a fast CPU. Recommended computer specifications: Intel Core i7 or better 32 GB RAM Nvidia GeForce GTX 1050 Ti or better Windows 10 x64 Prerequisites \u00b6 Trajectory File (see Trajectory Processing ) Processed point cloud (see Pointcloud Processing ) Quick Workflow \u00b6 Quick workflow is designed for fast LAS file production when the offsets and the calibration values are already stored in R1A. The R1A is delivered to customers fully calibrated. Therefore, the quick workflow is all that is needed 99% of the time. Navigate to the project folder and double click to open the ppk.pcmp file. ROCK-XXXX-[DATE]/Processing Files/ppk.pcpp This will load PCPainterGL and load all of the photos. Click Produce LAS and save the project when asked. Upload to the ROCK Cloud for post-processing Full Workflow \u00b6 In full workflow, designed for laser calibration and boresighting, the steps are: Click New Project \u2013 select the trajectory file, the scan files, and the digital images when asked. All scan files should be selected at the same time. PCPainterGL will load the data and pre-process scan files. It will also load the R1A orientation, the offsets and laser calibration values that were stored on R1A. The trajectory will be displayed, colored from blue at the beginning, to red at the end. Verify R1A orientation and that it matches the actual orientation of the unit (in relation to vehicle) during the scan. It should most likely match. Verify Linear offset and that it matches the reference values provided by the manufacturer. This is the offset between the IMU in the R1A and the digital camera. Verify the Angular offset and that it matches for the hardware setup used for the project being created. This angular offset is the offset between the IMU in the R1A and the camera being used. To ensure that camera images are correctly overlaid onto cloud points, enter in the Camera Lens Calibration settings in the Lens Calibration menu item. Right-click on segments of the trajectory file and select Switch to the camera here to view the photograph taken at that instance during the scan. Click Produce LAS and save the project when asked. Also, the project can be saved using Save Project and imported into R1A for storing the offsets and the calibration values. Batch Processing \u00b6 PCPainterGL can work with pre-created project files, where all the necessary values are already set. All it takes then is one button to produce a LAS file. It can even be scripted if PCPainterGL is run with the project file for argument and the batchoption. In that case, 3DView is not even shown, only the LAS files are produced based on the project file contents. PCMaster Project file format (PCPP) is simple XML with self-explanatory structure shown below and can be edited or generated by a script. Path selection is measured in tenths of a second and can be set to 0 for start and an insanely large number like 2,000,000,000 for finish to select the whole trajectory. PCPainterCL \u2013 Command Line Interface \u00b6 Versions of PCPainterGL after (and including) PCPainterGL version 1.0.0.1 by default include the ability to generate point clouds from the command line. After a project file has been created, the same project can be used to generate future clouds with the same configured settings using the command line which is much faster than directly using the graphical user interface. To do this, start by creating a project in PCPainterGL and configure the settings you would like to be applied for current and future clouds that will be generated. Save this project file to a location of your choice and right-click the project file and select Processto begin cloud generation from the command line. To run a particular project file from the command line simply use the following command: C:\\ (location of PCPainterGL.exe)\\> PCPainterCL.exe \\<path to the project file\\> User interface \u00b6 PCPainterGL has a very simple user interface with a near zero learning curve. The main window shows: Workflow control panel with buttons to perform actions on the current project, creating a new project, opening an existing one, saving it, changing offsets and calibration parameters and producing LAS files; Status bar showing the local plane position of the cursor and the dimensions of the measurement box Main 3D view showing current trajectory, currently enabled path segments and their point clouds, the local plane axes, the cursor focused on the current position and the measurement box if measurements are currently being taken The main 3D view can be controlled with as few as two mouse buttons, two keyboard keys and the mouse wheel. To look at the focus from different directions press and hold Left mouse button and move the mouse. To rotate the camera around its axis, press and hold Shift and Left mouse button and move the mouse. To move the focus horizontally, press and hold Ctrl and Left mouse button and move the mouse. To move the focus up and down, press and hold Ctrl, Shift and Left mouse button and move the mouse. To move the camera closer to the focus, scroll the mouse wheel forward. To move the camera away from the focus, scroll the mouse wheel back. To make perspective smaller (telephoto view) press and hold Shift and scroll the mouse wheel forward. To make perspective wider (wide-angle view) press and hold Shift and scroll the mouse wheel back. These field of view changes are useful when a long plane is looked at from its side. When the camera is in the telephoto mode, all parts of the plane have the same visible thickness with no perspective. This is very useful for laser calibration and offset adjustment. In this mode trackball rotations are also slowed down for fine adjustments. Right mouse button \u2013 when it is clicked, it opens the context menu with actions: Switch to the camera here: view the camera image overlaid on the cloud points below. Mouse buttons and wheel work the same way on touchpads, including multi-touch ones with mouse wheel modeled by zoom-in multi-touch pattern. Workflow Control Panel \u00b6 Workflow control buttons are: New Project \u2013 clears the current data if any and asks for the new trajectory and new scan files. New data are loaded, and the trajectory is displayed. Calibration values and offsets are taken from the R1A scan files; filters are cleared. Open Project \u2013 clears the current data and loads the trajectory and the scans from the selected project. Calibration values, offsets, and filters are loaded from the project file as well. Linear Offset \u2013 opens the panel showing the linear offset of the LiDAR reference point from the IMU reference point in the R1A reference frame. The changes immediately apply to the cloud. Angular Offset \u2013 opens the panel showing the alignment between the LiDAR and the R1A reference frame. The changes immediately apply to the cloud. R1A Orientation \u2013 opens the panel showing the R1A orientation in the vehicle reference frame. This should match the orientation entered in the R1A settings; it is recorded in the scan files and should not normally be changed unless the orientation was set incorrectly by mistake and had to be corrected in the trajectory generation software. Lens Calibration \u2013 opens the panel where camera lens calibration settings can be configured. The filters are discussed in the next section. Changes in the configuration apply immediately to the cloud. Save Project \u2013 saves the current state of the project to a project file. Produce LAS \u2013 produces the LAS file for every selected path checked for export, using points from every laser checked for export. Points are filtered through currently enabled filters. Project is automatically saved before production. The LAS files are saved in the cloudssub-folder in the folder where the project file is saved. Lens Calibration \u00b6 Camera Lens Calibration settings allow the user to clean up the point cloud by eliminating errors caused by camera lens parameters given by the manufacturer. The available settings are: Focal Length \u2013 is measured in millimeters and is dependent on the camera lens that is used and camera manufacturer restrictions. Pixel flatness \u2013 is measured in ppm and is the difference between vertical dimension and horizontal dimension of a pixel. Enter in the pixel flatness as given by camera manufacturer (default value is 0). RatPolyNum \u2013 restricts the area of overlay for the camera images projected onto cloud points. RatPolyDen \u2013 restricts the area of overlay for the camera images projected onto cloud points.","title":"Pointcloud Colorizing"},{"location":"pre-processing/colorizing/#point-cloud-colorizing","text":"","title":"Point Cloud Colorizing"},{"location":"pre-processing/colorizing/#key-features","text":"The key features of PCPainterGL are: Fast data processing On the fly point cloud visualization On the fly visualization of misalignment correction Point coloring by digital image overlay XML project format for ease of automation","title":"Key Features"},{"location":"pre-processing/colorizing/#platform-requirements","text":"PCPainterGL works on Windows 10 x64 (MacOS and Linux x64 versions are in development). The key requirement for seamless visualization of large point clouds is a fast GPU with large video memory (dedicated or shared). The software has been tested on nVidia GeForce GTX graphics cards, but it is hardware independent. The rule of thumb is 1 GB of memory for every 15 million points in the cloud. The current software limit is ~800 million points. Fast data processing also requires a fast CPU. Recommended computer specifications: Intel Core i7 or better 32 GB RAM Nvidia GeForce GTX 1050 Ti or better Windows 10 x64","title":"Platform Requirements"},{"location":"pre-processing/colorizing/#prerequisites","text":"Trajectory File (see Trajectory Processing ) Processed point cloud (see Pointcloud Processing )","title":"Prerequisites"},{"location":"pre-processing/colorizing/#quick-workflow","text":"Quick workflow is designed for fast LAS file production when the offsets and the calibration values are already stored in R1A. The R1A is delivered to customers fully calibrated. Therefore, the quick workflow is all that is needed 99% of the time. Navigate to the project folder and double click to open the ppk.pcmp file. ROCK-XXXX-[DATE]/Processing Files/ppk.pcpp This will load PCPainterGL and load all of the photos. Click Produce LAS and save the project when asked. Upload to the ROCK Cloud for post-processing","title":"Quick Workflow"},{"location":"pre-processing/colorizing/#full-workflow","text":"In full workflow, designed for laser calibration and boresighting, the steps are: Click New Project \u2013 select the trajectory file, the scan files, and the digital images when asked. All scan files should be selected at the same time. PCPainterGL will load the data and pre-process scan files. It will also load the R1A orientation, the offsets and laser calibration values that were stored on R1A. The trajectory will be displayed, colored from blue at the beginning, to red at the end. Verify R1A orientation and that it matches the actual orientation of the unit (in relation to vehicle) during the scan. It should most likely match. Verify Linear offset and that it matches the reference values provided by the manufacturer. This is the offset between the IMU in the R1A and the digital camera. Verify the Angular offset and that it matches for the hardware setup used for the project being created. This angular offset is the offset between the IMU in the R1A and the camera being used. To ensure that camera images are correctly overlaid onto cloud points, enter in the Camera Lens Calibration settings in the Lens Calibration menu item. Right-click on segments of the trajectory file and select Switch to the camera here to view the photograph taken at that instance during the scan. Click Produce LAS and save the project when asked. Also, the project can be saved using Save Project and imported into R1A for storing the offsets and the calibration values.","title":"Full Workflow"},{"location":"pre-processing/colorizing/#batch-processing","text":"PCPainterGL can work with pre-created project files, where all the necessary values are already set. All it takes then is one button to produce a LAS file. It can even be scripted if PCPainterGL is run with the project file for argument and the batchoption. In that case, 3DView is not even shown, only the LAS files are produced based on the project file contents. PCMaster Project file format (PCPP) is simple XML with self-explanatory structure shown below and can be edited or generated by a script. Path selection is measured in tenths of a second and can be set to 0 for start and an insanely large number like 2,000,000,000 for finish to select the whole trajectory.","title":"Batch Processing"},{"location":"pre-processing/colorizing/#pcpaintercl-command-line-interface","text":"Versions of PCPainterGL after (and including) PCPainterGL version 1.0.0.1 by default include the ability to generate point clouds from the command line. After a project file has been created, the same project can be used to generate future clouds with the same configured settings using the command line which is much faster than directly using the graphical user interface. To do this, start by creating a project in PCPainterGL and configure the settings you would like to be applied for current and future clouds that will be generated. Save this project file to a location of your choice and right-click the project file and select Processto begin cloud generation from the command line. To run a particular project file from the command line simply use the following command: C:\\ (location of PCPainterGL.exe)\\> PCPainterCL.exe \\<path to the project file\\>","title":"PCPainterCL \u2013 Command Line Interface"},{"location":"pre-processing/colorizing/#user-interface","text":"PCPainterGL has a very simple user interface with a near zero learning curve. The main window shows: Workflow control panel with buttons to perform actions on the current project, creating a new project, opening an existing one, saving it, changing offsets and calibration parameters and producing LAS files; Status bar showing the local plane position of the cursor and the dimensions of the measurement box Main 3D view showing current trajectory, currently enabled path segments and their point clouds, the local plane axes, the cursor focused on the current position and the measurement box if measurements are currently being taken The main 3D view can be controlled with as few as two mouse buttons, two keyboard keys and the mouse wheel. To look at the focus from different directions press and hold Left mouse button and move the mouse. To rotate the camera around its axis, press and hold Shift and Left mouse button and move the mouse. To move the focus horizontally, press and hold Ctrl and Left mouse button and move the mouse. To move the focus up and down, press and hold Ctrl, Shift and Left mouse button and move the mouse. To move the camera closer to the focus, scroll the mouse wheel forward. To move the camera away from the focus, scroll the mouse wheel back. To make perspective smaller (telephoto view) press and hold Shift and scroll the mouse wheel forward. To make perspective wider (wide-angle view) press and hold Shift and scroll the mouse wheel back. These field of view changes are useful when a long plane is looked at from its side. When the camera is in the telephoto mode, all parts of the plane have the same visible thickness with no perspective. This is very useful for laser calibration and offset adjustment. In this mode trackball rotations are also slowed down for fine adjustments. Right mouse button \u2013 when it is clicked, it opens the context menu with actions: Switch to the camera here: view the camera image overlaid on the cloud points below. Mouse buttons and wheel work the same way on touchpads, including multi-touch ones with mouse wheel modeled by zoom-in multi-touch pattern.","title":"User interface"},{"location":"pre-processing/colorizing/#workflow-control-panel","text":"Workflow control buttons are: New Project \u2013 clears the current data if any and asks for the new trajectory and new scan files. New data are loaded, and the trajectory is displayed. Calibration values and offsets are taken from the R1A scan files; filters are cleared. Open Project \u2013 clears the current data and loads the trajectory and the scans from the selected project. Calibration values, offsets, and filters are loaded from the project file as well. Linear Offset \u2013 opens the panel showing the linear offset of the LiDAR reference point from the IMU reference point in the R1A reference frame. The changes immediately apply to the cloud. Angular Offset \u2013 opens the panel showing the alignment between the LiDAR and the R1A reference frame. The changes immediately apply to the cloud. R1A Orientation \u2013 opens the panel showing the R1A orientation in the vehicle reference frame. This should match the orientation entered in the R1A settings; it is recorded in the scan files and should not normally be changed unless the orientation was set incorrectly by mistake and had to be corrected in the trajectory generation software. Lens Calibration \u2013 opens the panel where camera lens calibration settings can be configured. The filters are discussed in the next section. Changes in the configuration apply immediately to the cloud. Save Project \u2013 saves the current state of the project to a project file. Produce LAS \u2013 produces the LAS file for every selected path checked for export, using points from every laser checked for export. Points are filtered through currently enabled filters. Project is automatically saved before production. The LAS files are saved in the cloudssub-folder in the folder where the project file is saved.","title":"Workflow Control Panel"},{"location":"pre-processing/colorizing/#lens-calibration","text":"Camera Lens Calibration settings allow the user to clean up the point cloud by eliminating errors caused by camera lens parameters given by the manufacturer. The available settings are: Focal Length \u2013 is measured in millimeters and is dependent on the camera lens that is used and camera manufacturer restrictions. Pixel flatness \u2013 is measured in ppm and is the difference between vertical dimension and horizontal dimension of a pixel. Enter in the pixel flatness as given by camera manufacturer (default value is 0). RatPolyNum \u2013 restricts the area of overlay for the camera images projected onto cloud points. RatPolyDen \u2013 restricts the area of overlay for the camera images projected onto cloud points.","title":"Lens Calibration"},{"location":"pre-processing/introduction/","text":"Introduction \u00b6 The ROCK Robotic R1A consists of a LiDAR and an INS. The data gathered from both devices must be fused together to get LiDAR points geo-referenced \u2013 transformed from the LiDAR reference frame to geographic coordinates. The steps for taking the raw data and converting it to a point cloud are as follows: Create a highly accurate trajectory Use that trajectory to create the point cloud (Optional) Colorize the point cloud with imagery. Platform Requirements \u00b6 PCMasterGL works on Windows 10 x64 (MacOS and Linux x64 versions are in development). The key requirement for seamless visualization of large point clouds is a fast GPU with large video memory (dedicated or shared). The software has been tested on nVidia GeForce GTX graphics cards, but it is hardware independent. The rule of thumb is 1 GB of memory for every 15 million points in the cloud. The current software limit is 800 million points. Fast data processing also requires a fast CPU. Recommended computer specifications: Intel Core i7 or better 32 GB RAM Nvidia GeForce GTX 1050 Ti or better Windows 10 x64 Step 1 - Create a highly accurate trajectory","title":"Introduction"},{"location":"pre-processing/introduction/#introduction","text":"The ROCK Robotic R1A consists of a LiDAR and an INS. The data gathered from both devices must be fused together to get LiDAR points geo-referenced \u2013 transformed from the LiDAR reference frame to geographic coordinates. The steps for taking the raw data and converting it to a point cloud are as follows: Create a highly accurate trajectory Use that trajectory to create the point cloud (Optional) Colorize the point cloud with imagery.","title":"Introduction"},{"location":"pre-processing/introduction/#platform-requirements","text":"PCMasterGL works on Windows 10 x64 (MacOS and Linux x64 versions are in development). The key requirement for seamless visualization of large point clouds is a fast GPU with large video memory (dedicated or shared). The software has been tested on nVidia GeForce GTX graphics cards, but it is hardware independent. The rule of thumb is 1 GB of memory for every 15 million points in the cloud. The current software limit is 800 million points. Fast data processing also requires a fast CPU. Recommended computer specifications: Intel Core i7 or better 32 GB RAM Nvidia GeForce GTX 1050 Ti or better Windows 10 x64 Step 1 - Create a highly accurate trajectory","title":"Platform Requirements"},{"location":"pre-processing/point-cloud-processing/","text":"Point Cloud Processing \u00b6 Overview \u00b6 The ROCK Robotic R1A consists of a LiDAR and an INS. The data gathered from both devices must be fused together to get LiDAR points geo-referenced \u2013 transformed from the LiDAR reference frame to geographic coordinates. The PCMasterGL software is designed just for that. Additionally, it observes and corrects for misalignments between the INS and the lasers of the LiDAR. PCMasterGL software takes INS trajectory generated by a Post-Processed Kinematics software and LiDAR scan files generated by R1A system and converts them to point clouds in LAS format for further processing. Two workflows are possible: full workflow for checking and adjusting misalignments; and quick workflow for cases when the system was previously calibrated, and the calibration data is stored on the R1A. The latter can be further sped up to batch workflow using a pre-defined project and zero user input. Platform Requirements \u00b6 PCMasterGL works on Windows 10 x64 (MacOS and Linux x64 versions are in development). The key requirement for seamless visualization of large point clouds is a fast GPU with large video memory (dedicated or shared). The software has been tested on nVidia GeForce GTX graphics cards, but it is hardware independent. The rule of thumb is 1 GB of memory for every 15 million points in the cloud. The current software limit is ~800 million points. Fast data processing also requires a fast CPU. Recommended computer specifications: Intel Core i7 or better 32 GB RAM Nvidia GeForce GTX 1050 Ti or better Windows 10 x64 Prerequisites \u00b6 Trajectory File (see Trajectory Processing ) Quick Workflow \u00b6 Quick workflow is designed for fast LAS file production when the offsets and the calibration values are already stored in R1A. The R1A is delivered to customers fully calibrated. Therefore, the quick workflow is all that is needed 99% of the time. Move the project data from the USB stick to your local hard-drive. This will ensure the highest speed of processing. Navigate to the project folder and double click to open the ppk.pcmp file. ROCK-XXXX-[DATE]/Processing Files/ppk.pcmp This will open up PCMasterGL with your project files and the trajectory that you processed in the previous step. Once the trajectory appears it should look similar to: Right-click at the blue end of the trajectory and select \" Start selection here \". Right-click at the red end of the trajectory and select \" Finish selection here \". Make Sure You want to start your selection at the beginning of your flight line and finish your selection at the end of the data acquisition portion of the flight. This means that the calibration part of the flight at the beginning and the flight back to the landing zone should not be included. Your first selection will now look like this: Slow If you have an underpowered processing computer you can select Lasers and uncheck Display to prevent PCMasterGL from rendering all of the laser points. If you required a battery change in the middle of your flight, then select multiple start/stop combinations so that only the flight lines over the data acquisition target are included in the selections. Click Cloud Filter . Set the distance filter so that false points very close to the sensor are ignored. Here I selected to keep points which are betwee 4 and 200 meters from the sensor. Click Produce LAS and save the project when asked. You now have an LAS file! If you have a co-aligned camera, then proceed to Pointcloud Colorizing Otherwise Upload to the ROCK Cloud for post-processing Full Workflow \u00b6 Full workflow is designed for scans where the misalignment angles are to be checked or adjusted. The workflow consists of the following steps: Trajectory loading Scan files loading Linear offset verification Calibration path selection according to guidelines outlined in R1A Boresighting Manual LiDAR boresighting using one laser Laser calibration for all other lasers Path selection for point cloud export Optional cloud filter configuration LAS export In full workflow, designed for laser calibration and boresighting, the steps are: Click \" New Project \" \u2013 select the trajectory file and the scan files when asked. All scan files should be selected at the same time. PCMasterGL will load the data and pre-process scan files. It will also load the R1A orientation, the offsets and laser calibration values that were stored on R1A. The trajectory will be displayed, colored from blue at the beginning, to red at the end. Verify R1A orientation and that it matches the actual orientation of the unit during the scan. It should most likely match. Verify Linear offset and that it matches the reference values provided by the manufacturer. Find a place in the trajectory where calibration values can be observed, per R1A Boresighting Manual. Select the paths in the opposite directions in both legs of the boresighting pattern as separate segments: Right-click on the beginning of the trajectory segment and select \" Start selection here \". If the position is incorrect, Right-click on the correct position and select \" Restart selection here \". Right-click on the other end of the trajectory segment and select \" Finish selection here \". PCMasterGL will highlight the selected segment and display the point cloud obtained for this segment, colored the same as the segment highlight. Repeat these steps for the other three segments of the boresighting path. Click the \" Lasers \" button and select the reference laser to adjust angular offsets. It should be a laser producing tilted lines. Depending on the R1A orientation, it can be laser 0, or laser 1, or laser 15 (for VLP-16 LiDAR). Ensure the \" Azimuth \" value is zero for the reference laser. Uncheck \" Display \" for all other lasers. The point clouds will only show the selected laser then. Click the \" Paths \"button and select the two path segments going in the opposite directions, say East and West, for example. Uncheck \" Display \"for all other paths. PCMasterGL will only display the selected paths. Turn the view in such a way so it looks along the bottom edge of the vertical wall. Observe the vertical mismatch between the path clouds. Click \" Angular Offset \" and adjust the Roll offset while observing the clouds moving. Use PgUp or PgDn to change the value by 0.1 degree and Up or Down to change by 0.01 degree. Hint: The offset window can be moved away from the main window and kept open while doing other adjustments. Another hint: Use the mouse wheel with Shift to get the telephoto view with no perspective for better observability of mismatch. Rotate the view to look along the vertical edge, open the \" Lasers \" window and adjust the \" Elevation \" offset of the reference laser to align the vertical edges. The wall planes may be misaligned because of the Yaw offset of the LiDAR, which will be adjusted later. Hint: the laser controls window can be kept open while adjusting other values as well. If the wall edges are aligned at the bottom but not aligned at the top, adjust the \" Pitch \" offset to align them. Select the other two paths and align all four vertical edges by adjusting the \" Yaw \" offset. Select other lasers one by one and adjust their \" Azimuth \"offsets, aligning the horizontal edges; and their \" Elevation \" offsets, aligning the vertical edges of the same wall. Verify the quality of calibration by selecting all lasers together and verifying that all clouds are aligned. Now the calibration segments can be removed by clicking \" Delete \" for each of them in the Path controls window. Then the full trajectory can be selected for LAS file export as in the next section for Quick workflow. Also, the project can be saved using \" Save Project \" and imported into R1A for storing the offsets and the calibration values. Batch Processing \u00b6 PCMasterGL can work with pre-created project files, where all the necessary values are already set. All it takes then is one button to produce a LAS file. It can even be scripted if PCMasterGL is run with the project file for argument and the \"batch\" option. In that case, 3DView is not even shown, only the LAS files are produced based on the project file contents. PCMaster Project file format (PCMP) is simple XML with self-explanatory structure shown below and can be edited or generated by a script. Path selection is measured in tenths of a second and can be set to 0 for start and an insanely large number like 2,000,000,000 for finish to select the whole trajectory. PCMasterCL \u2013 Command Line Interface \u00b6 Versions of PCMasterGL after (and including) PCMasterGL version 1.5.2.1 by default include the ability to generate point clouds from the command line. After a project file has been created, the same project can be used to generate future clouds with the same configured settings using the command line which is much faster than directly using the graphical user interface. To do this, start by creating a project in PCMasterGL and configure the settings you would like to be applied for current and future clouds that will be generated. Save this project file to a location of your choice and right-click the project file and select \"Process\" to begin cloud generation from the command line. To run a particular project file from the command line simply use the following command: C:\\ (location of PCMasterGL.exe)\\> PCMasterCL.exe \\<path to the project file\\> Step 3 - Pointcloud Colorizing User Interface \u00b6 PCMasterGL has a very simple user interface with a near zero learning curve. The main window is shown below. The main window shows: Workflow control panel with buttons to perform actions on the current project, creating a new project, opening an existing one, saving it, changing filters and producing LAS files button to toggle display of different path segments on and off button to toggle display of different lasers on and off, and to adjust calibration of each laser buttons to adjust offsets Status bar showing the local plane position of the cursor and the dimensions of the measurement box Main 3D view showing current trajectory, currently enabled path segments and their point clouds from currently enabled lasers, the local plane axes, the cursor focused on the current position and the measurement box if measurements are currently being taken The main 3D view can be controlled with as few as two mouse buttons, two keyboard keys and the mouse wheel. To look at the focus from different directions press and hold Left mouse button and move the mouse. To rotate the camera around its axis, press and hold Shift and Left mouse button and move the mouse. To move the focus horizontally, press and hold Ctrl and Left mouse button and move the mouse. To move the focus up and down, press and hold Ctrl, Shift and Left mouse button and move the mouse. To move the camera closer to the focus, scroll the mouse wheel forward. To move the camera away from the focus, scroll the mouse wheel back. To make perspective smaller (telephoto view) press and hold Shift and scroll the mouse wheel forward . To make perspective wider (wide-angle view) press and hold Shift and scroll the mouse wheel back . These field of view changes are useful when a long plane is looked at from its side. When the camera is in the telephoto mode, all parts of the plane have the same visible thickness with no perspective. This is very useful for laser calibration and offset adjustment. In this mode trackball rotations are also slowed down for fine adjustments. Right mouse button \u2013 when it is clicked, it opens the context menu with actions: Start, restart, or finish new path segment selection at the point where the mouse is now; Start, restart measurement at the current focus point or stop measurement; Switch point cloud coloring between by-segment and by-laser. Mouse buttons and wheel work the same way on touchpads, including multi-touch ones with mouse wheel modeled by zoom-in multi-touch pattern. Workflow Control Panel \u00b6 Workflow control buttons are: New Project \u2013 clears the current data if any and asks for the new trajectory and new scan files. New data are loaded, and the trajectory is displayed. Calibration values and offsets are taken from the R1A scan files; filters are cleared. Open Project \u2013 clears the current data and loads the trajectory and the scans from the selected project. The paths and the lasers are selected for display and export as specified in the project. Calibration values, offsets, and filters are loaded from the project file as well. Paths \u2013 opens the list of currently selected trajectory segments with their display colors. Each can be checked and unchecked for display and for export, and each can be removed using the Remove action button. Lasers \u2013 opens the list of lasers in the scan files and their calibration values. Each can be checked and unchecked for display or export, and each calibration value can be adjusted. Adjusted values are immediately applied to the point clouds in the main view. Linear Offset \u2013 opens the panel showing the linear offset of the LiDAR reference point from the IMU reference point in the R1A reference frame. The changes immediately apply to the cloud. Angular Offset \u2013 opens the panel showing the alignment between the LiDAR and the R1A reference frame. The changes immediately apply to the cloud. R1A Orientation \u2013 opens the panel showing the R1A orientation in the vehicle reference frame. This should match the orientation entered in the R1A settings; it is recorded in the scan files and should not normally be changed unless the orientation was set incorrectly by mistake and had to be corrected in the trajectory generation software. Cloud Filter \u2013 opens the panel where filters can be enabled and configured. The filters are discussed in the next section. Changes in the configuration apply immediately to the cloud. Save Project \u2013 saves the current state of the project to a project file. Produce LAS \u2013 produces the LAS file for every selected path checked for export, using points from every laser checked for export. Points are filtered through currently enabled filters. Project is automatically saved before production. The LAS files are saved in the \"clouds\" sub-folder in the folder where the project file is saved. Cloud Filters \u00b6 Cloud filters allow users to clean up the point cloud by eliminating points produced by reflections and some distortion points caused by high angular rates of the vehicle. The filters are: Rotation angle filter restricts the cloud to points obtained from lidar when its reported rotation angle is between the minimum and the maximum value. For example, when a UAV flies above the ground, only points from the sector below the UAV make sense. Thus, the range can be limited to some 120-150 degrees around the nadir. If the range around 360 degrees is desired, the left value should be set larger than the right value. That way, the range will be limited from the left value to 360 degrees plus from 0 degrees to the right value. Distance filter restricts the cloud to points within a certain distance range from the LiDAR in meters. This is useful for filtering out reflections from the car roof by setting the left value to some 2 meters and the right to some insanely large value. Reflectivity filter restricts the clouds to points within certain reflectivity range. Angular rate filter restricts the clouds to points taken when the R1A was turning slower than the set value in degrees per second. Easting, Northing, and Altitude filters simply reject points that are outside the set boundaries in meters.","title":"Pointcloud Processing"},{"location":"pre-processing/point-cloud-processing/#point-cloud-processing","text":"","title":"Point Cloud Processing"},{"location":"pre-processing/point-cloud-processing/#overview","text":"The ROCK Robotic R1A consists of a LiDAR and an INS. The data gathered from both devices must be fused together to get LiDAR points geo-referenced \u2013 transformed from the LiDAR reference frame to geographic coordinates. The PCMasterGL software is designed just for that. Additionally, it observes and corrects for misalignments between the INS and the lasers of the LiDAR. PCMasterGL software takes INS trajectory generated by a Post-Processed Kinematics software and LiDAR scan files generated by R1A system and converts them to point clouds in LAS format for further processing. Two workflows are possible: full workflow for checking and adjusting misalignments; and quick workflow for cases when the system was previously calibrated, and the calibration data is stored on the R1A. The latter can be further sped up to batch workflow using a pre-defined project and zero user input.","title":"Overview"},{"location":"pre-processing/point-cloud-processing/#platform-requirements","text":"PCMasterGL works on Windows 10 x64 (MacOS and Linux x64 versions are in development). The key requirement for seamless visualization of large point clouds is a fast GPU with large video memory (dedicated or shared). The software has been tested on nVidia GeForce GTX graphics cards, but it is hardware independent. The rule of thumb is 1 GB of memory for every 15 million points in the cloud. The current software limit is ~800 million points. Fast data processing also requires a fast CPU. Recommended computer specifications: Intel Core i7 or better 32 GB RAM Nvidia GeForce GTX 1050 Ti or better Windows 10 x64","title":"Platform Requirements"},{"location":"pre-processing/point-cloud-processing/#prerequisites","text":"Trajectory File (see Trajectory Processing )","title":"Prerequisites"},{"location":"pre-processing/point-cloud-processing/#quick-workflow","text":"Quick workflow is designed for fast LAS file production when the offsets and the calibration values are already stored in R1A. The R1A is delivered to customers fully calibrated. Therefore, the quick workflow is all that is needed 99% of the time. Move the project data from the USB stick to your local hard-drive. This will ensure the highest speed of processing. Navigate to the project folder and double click to open the ppk.pcmp file. ROCK-XXXX-[DATE]/Processing Files/ppk.pcmp This will open up PCMasterGL with your project files and the trajectory that you processed in the previous step. Once the trajectory appears it should look similar to: Right-click at the blue end of the trajectory and select \" Start selection here \". Right-click at the red end of the trajectory and select \" Finish selection here \". Make Sure You want to start your selection at the beginning of your flight line and finish your selection at the end of the data acquisition portion of the flight. This means that the calibration part of the flight at the beginning and the flight back to the landing zone should not be included. Your first selection will now look like this: Slow If you have an underpowered processing computer you can select Lasers and uncheck Display to prevent PCMasterGL from rendering all of the laser points. If you required a battery change in the middle of your flight, then select multiple start/stop combinations so that only the flight lines over the data acquisition target are included in the selections. Click Cloud Filter . Set the distance filter so that false points very close to the sensor are ignored. Here I selected to keep points which are betwee 4 and 200 meters from the sensor. Click Produce LAS and save the project when asked. You now have an LAS file! If you have a co-aligned camera, then proceed to Pointcloud Colorizing Otherwise Upload to the ROCK Cloud for post-processing","title":"Quick Workflow"},{"location":"pre-processing/point-cloud-processing/#full-workflow","text":"Full workflow is designed for scans where the misalignment angles are to be checked or adjusted. The workflow consists of the following steps: Trajectory loading Scan files loading Linear offset verification Calibration path selection according to guidelines outlined in R1A Boresighting Manual LiDAR boresighting using one laser Laser calibration for all other lasers Path selection for point cloud export Optional cloud filter configuration LAS export In full workflow, designed for laser calibration and boresighting, the steps are: Click \" New Project \" \u2013 select the trajectory file and the scan files when asked. All scan files should be selected at the same time. PCMasterGL will load the data and pre-process scan files. It will also load the R1A orientation, the offsets and laser calibration values that were stored on R1A. The trajectory will be displayed, colored from blue at the beginning, to red at the end. Verify R1A orientation and that it matches the actual orientation of the unit during the scan. It should most likely match. Verify Linear offset and that it matches the reference values provided by the manufacturer. Find a place in the trajectory where calibration values can be observed, per R1A Boresighting Manual. Select the paths in the opposite directions in both legs of the boresighting pattern as separate segments: Right-click on the beginning of the trajectory segment and select \" Start selection here \". If the position is incorrect, Right-click on the correct position and select \" Restart selection here \". Right-click on the other end of the trajectory segment and select \" Finish selection here \". PCMasterGL will highlight the selected segment and display the point cloud obtained for this segment, colored the same as the segment highlight. Repeat these steps for the other three segments of the boresighting path. Click the \" Lasers \" button and select the reference laser to adjust angular offsets. It should be a laser producing tilted lines. Depending on the R1A orientation, it can be laser 0, or laser 1, or laser 15 (for VLP-16 LiDAR). Ensure the \" Azimuth \" value is zero for the reference laser. Uncheck \" Display \" for all other lasers. The point clouds will only show the selected laser then. Click the \" Paths \"button and select the two path segments going in the opposite directions, say East and West, for example. Uncheck \" Display \"for all other paths. PCMasterGL will only display the selected paths. Turn the view in such a way so it looks along the bottom edge of the vertical wall. Observe the vertical mismatch between the path clouds. Click \" Angular Offset \" and adjust the Roll offset while observing the clouds moving. Use PgUp or PgDn to change the value by 0.1 degree and Up or Down to change by 0.01 degree. Hint: The offset window can be moved away from the main window and kept open while doing other adjustments. Another hint: Use the mouse wheel with Shift to get the telephoto view with no perspective for better observability of mismatch. Rotate the view to look along the vertical edge, open the \" Lasers \" window and adjust the \" Elevation \" offset of the reference laser to align the vertical edges. The wall planes may be misaligned because of the Yaw offset of the LiDAR, which will be adjusted later. Hint: the laser controls window can be kept open while adjusting other values as well. If the wall edges are aligned at the bottom but not aligned at the top, adjust the \" Pitch \" offset to align them. Select the other two paths and align all four vertical edges by adjusting the \" Yaw \" offset. Select other lasers one by one and adjust their \" Azimuth \"offsets, aligning the horizontal edges; and their \" Elevation \" offsets, aligning the vertical edges of the same wall. Verify the quality of calibration by selecting all lasers together and verifying that all clouds are aligned. Now the calibration segments can be removed by clicking \" Delete \" for each of them in the Path controls window. Then the full trajectory can be selected for LAS file export as in the next section for Quick workflow. Also, the project can be saved using \" Save Project \" and imported into R1A for storing the offsets and the calibration values.","title":"Full Workflow"},{"location":"pre-processing/point-cloud-processing/#batch-processing","text":"PCMasterGL can work with pre-created project files, where all the necessary values are already set. All it takes then is one button to produce a LAS file. It can even be scripted if PCMasterGL is run with the project file for argument and the \"batch\" option. In that case, 3DView is not even shown, only the LAS files are produced based on the project file contents. PCMaster Project file format (PCMP) is simple XML with self-explanatory structure shown below and can be edited or generated by a script. Path selection is measured in tenths of a second and can be set to 0 for start and an insanely large number like 2,000,000,000 for finish to select the whole trajectory.","title":"Batch Processing"},{"location":"pre-processing/point-cloud-processing/#pcmastercl-command-line-interface","text":"Versions of PCMasterGL after (and including) PCMasterGL version 1.5.2.1 by default include the ability to generate point clouds from the command line. After a project file has been created, the same project can be used to generate future clouds with the same configured settings using the command line which is much faster than directly using the graphical user interface. To do this, start by creating a project in PCMasterGL and configure the settings you would like to be applied for current and future clouds that will be generated. Save this project file to a location of your choice and right-click the project file and select \"Process\" to begin cloud generation from the command line. To run a particular project file from the command line simply use the following command: C:\\ (location of PCMasterGL.exe)\\> PCMasterCL.exe \\<path to the project file\\> Step 3 - Pointcloud Colorizing","title":"PCMasterCL \u2013 Command Line Interface"},{"location":"pre-processing/point-cloud-processing/#user-interface","text":"PCMasterGL has a very simple user interface with a near zero learning curve. The main window is shown below. The main window shows: Workflow control panel with buttons to perform actions on the current project, creating a new project, opening an existing one, saving it, changing filters and producing LAS files button to toggle display of different path segments on and off button to toggle display of different lasers on and off, and to adjust calibration of each laser buttons to adjust offsets Status bar showing the local plane position of the cursor and the dimensions of the measurement box Main 3D view showing current trajectory, currently enabled path segments and their point clouds from currently enabled lasers, the local plane axes, the cursor focused on the current position and the measurement box if measurements are currently being taken The main 3D view can be controlled with as few as two mouse buttons, two keyboard keys and the mouse wheel. To look at the focus from different directions press and hold Left mouse button and move the mouse. To rotate the camera around its axis, press and hold Shift and Left mouse button and move the mouse. To move the focus horizontally, press and hold Ctrl and Left mouse button and move the mouse. To move the focus up and down, press and hold Ctrl, Shift and Left mouse button and move the mouse. To move the camera closer to the focus, scroll the mouse wheel forward. To move the camera away from the focus, scroll the mouse wheel back. To make perspective smaller (telephoto view) press and hold Shift and scroll the mouse wheel forward . To make perspective wider (wide-angle view) press and hold Shift and scroll the mouse wheel back . These field of view changes are useful when a long plane is looked at from its side. When the camera is in the telephoto mode, all parts of the plane have the same visible thickness with no perspective. This is very useful for laser calibration and offset adjustment. In this mode trackball rotations are also slowed down for fine adjustments. Right mouse button \u2013 when it is clicked, it opens the context menu with actions: Start, restart, or finish new path segment selection at the point where the mouse is now; Start, restart measurement at the current focus point or stop measurement; Switch point cloud coloring between by-segment and by-laser. Mouse buttons and wheel work the same way on touchpads, including multi-touch ones with mouse wheel modeled by zoom-in multi-touch pattern.","title":"User Interface"},{"location":"pre-processing/point-cloud-processing/#workflow-control-panel","text":"Workflow control buttons are: New Project \u2013 clears the current data if any and asks for the new trajectory and new scan files. New data are loaded, and the trajectory is displayed. Calibration values and offsets are taken from the R1A scan files; filters are cleared. Open Project \u2013 clears the current data and loads the trajectory and the scans from the selected project. The paths and the lasers are selected for display and export as specified in the project. Calibration values, offsets, and filters are loaded from the project file as well. Paths \u2013 opens the list of currently selected trajectory segments with their display colors. Each can be checked and unchecked for display and for export, and each can be removed using the Remove action button. Lasers \u2013 opens the list of lasers in the scan files and their calibration values. Each can be checked and unchecked for display or export, and each calibration value can be adjusted. Adjusted values are immediately applied to the point clouds in the main view. Linear Offset \u2013 opens the panel showing the linear offset of the LiDAR reference point from the IMU reference point in the R1A reference frame. The changes immediately apply to the cloud. Angular Offset \u2013 opens the panel showing the alignment between the LiDAR and the R1A reference frame. The changes immediately apply to the cloud. R1A Orientation \u2013 opens the panel showing the R1A orientation in the vehicle reference frame. This should match the orientation entered in the R1A settings; it is recorded in the scan files and should not normally be changed unless the orientation was set incorrectly by mistake and had to be corrected in the trajectory generation software. Cloud Filter \u2013 opens the panel where filters can be enabled and configured. The filters are discussed in the next section. Changes in the configuration apply immediately to the cloud. Save Project \u2013 saves the current state of the project to a project file. Produce LAS \u2013 produces the LAS file for every selected path checked for export, using points from every laser checked for export. Points are filtered through currently enabled filters. Project is automatically saved before production. The LAS files are saved in the \"clouds\" sub-folder in the folder where the project file is saved.","title":"Workflow Control Panel"},{"location":"pre-processing/point-cloud-processing/#cloud-filters","text":"Cloud filters allow users to clean up the point cloud by eliminating points produced by reflections and some distortion points caused by high angular rates of the vehicle. The filters are: Rotation angle filter restricts the cloud to points obtained from lidar when its reported rotation angle is between the minimum and the maximum value. For example, when a UAV flies above the ground, only points from the sector below the UAV make sense. Thus, the range can be limited to some 120-150 degrees around the nadir. If the range around 360 degrees is desired, the left value should be set larger than the right value. That way, the range will be limited from the left value to 360 degrees plus from 0 degrees to the right value. Distance filter restricts the cloud to points within a certain distance range from the LiDAR in meters. This is useful for filtering out reflections from the car roof by setting the left value to some 2 meters and the right to some insanely large value. Reflectivity filter restricts the clouds to points within certain reflectivity range. Angular rate filter restricts the clouds to points taken when the R1A was turning slower than the set value in degrees per second. Easting, Northing, and Altitude filters simply reject points that are outside the set boundaries in meters.","title":"Cloud Filters"},{"location":"pre-processing/trajectory-processing/","text":"Trajectory Processing \u00b6 In order to have a highly accurate point cloud the exact position of the LiDAR unit must be calculated. Inertial Explorer is used to create this highly accurate position file. Prerequisits \u00b6 Inertial Explorer installed on your computer Data from an R1A LiDAR scan A base station RINEX file The precise position of the base station Install Inertial Explorer User Settings \u00b6 After Inertial Explorer is installed for the first time you will need to apply some user settings. Download configuration files Unzip and place these configuration files inside C:\\NovAtel\\InertialExplorer890\\resources\\User Process Trajectory \u00b6 Start Inertial Explorer Select File -> New Project -> Project Wizard Welcome to the Project Wizard (click 'Next') Browse and select the 'Rover' data. This data will be found in the ROCK folder on the R1A thumbdrive. The file will end with -gnss.gps Select the checkbox 'I have IMU data file in Waypoint (IMR) format'. Browse and select the -imu.imr file inside the ROCK folder. Click 'Next' Remote (Rover) Antenna Height -- Do not change settings, simply click 'Next' Base (Master) Stations -- Select 'Add Station from File' -> 'Next' Browse and select the *.obs RINEX file that you recorded from your base station. Base (Master) Station Information Enter the precise coordinates of the base station. Enter the precise height of the base station antenna above the ground in 'Measured height'. NOTE: This is the height of the tripod plus the height from the bottom of your receiver to the antenna. Your GNSS receiver manufacturer will tell you the height from the bottom of the receiver to the antenna. For instance, the EMLID Reach RS2 is .134 meters. Then click 'Next' Base (Master) Stations Click 'Next' Project Overview Click 'Finish' Unprocessed Map You will now see the unprocessed trajectory like this: Process TC (Tightly Coupled) Select Process -> Process TC (Tightly Coupled) In Processing Settings select: Processing Direction 'Both' and Multi-pass 'IL INS (UAV)' profile De-select 'Read rotations and lever arms from IMR file' The first time processing data with the R1A on a particular drone, you need to 'Solve lever arm' Click the down arrow next to 'Process' and select 'Solve lever arm' This will determine the X, Y, Z offset for the gnss antenna to the IMU. You will want to 'Solve lever arm' multiple times. Between each run select the 'Average' and run again. After 3 or 4 times the lever arm will converge and you will know the lever arm. Once the lever arm is determined, you can create a vehicle profile so you wont have to calculate the lever arm again. Now click 'Process' If pre-processing checks pop up, select 'Try to fix the issue(s) before processing' -> Continue Export Wizard Once processing is complete select 'Output' -> 'Export Wizard' Name the exported file and select PCMasterGL in the profile -> Next File name and Location In order for the next processing steps to work smoothly, ensure you place the exported file in the pre-created 'ins' directory and name the file 'ppk.txt'. It should look like this ROCK-XXXX-[DATE]/ins/ppk.txt Select 'Use processing datum' -> Next IMU Epoch Settings -> Finish You will now have a highly refined trajectory file that you can use with PCMasterGL. Step 2 - Create the pointcloud","title":"Trajectory Processing"},{"location":"pre-processing/trajectory-processing/#trajectory-processing","text":"In order to have a highly accurate point cloud the exact position of the LiDAR unit must be calculated. Inertial Explorer is used to create this highly accurate position file.","title":"Trajectory Processing"},{"location":"pre-processing/trajectory-processing/#prerequisits","text":"Inertial Explorer installed on your computer Data from an R1A LiDAR scan A base station RINEX file The precise position of the base station","title":"Prerequisits"},{"location":"pre-processing/trajectory-processing/#install-inertial-explorer-user-settings","text":"After Inertial Explorer is installed for the first time you will need to apply some user settings. Download configuration files Unzip and place these configuration files inside C:\\NovAtel\\InertialExplorer890\\resources\\User","title":"Install Inertial Explorer User Settings"},{"location":"pre-processing/trajectory-processing/#process-trajectory","text":"Start Inertial Explorer Select File -> New Project -> Project Wizard Welcome to the Project Wizard (click 'Next') Browse and select the 'Rover' data. This data will be found in the ROCK folder on the R1A thumbdrive. The file will end with -gnss.gps Select the checkbox 'I have IMU data file in Waypoint (IMR) format'. Browse and select the -imu.imr file inside the ROCK folder. Click 'Next' Remote (Rover) Antenna Height -- Do not change settings, simply click 'Next' Base (Master) Stations -- Select 'Add Station from File' -> 'Next' Browse and select the *.obs RINEX file that you recorded from your base station. Base (Master) Station Information Enter the precise coordinates of the base station. Enter the precise height of the base station antenna above the ground in 'Measured height'. NOTE: This is the height of the tripod plus the height from the bottom of your receiver to the antenna. Your GNSS receiver manufacturer will tell you the height from the bottom of the receiver to the antenna. For instance, the EMLID Reach RS2 is .134 meters. Then click 'Next' Base (Master) Stations Click 'Next' Project Overview Click 'Finish' Unprocessed Map You will now see the unprocessed trajectory like this: Process TC (Tightly Coupled) Select Process -> Process TC (Tightly Coupled) In Processing Settings select: Processing Direction 'Both' and Multi-pass 'IL INS (UAV)' profile De-select 'Read rotations and lever arms from IMR file' The first time processing data with the R1A on a particular drone, you need to 'Solve lever arm' Click the down arrow next to 'Process' and select 'Solve lever arm' This will determine the X, Y, Z offset for the gnss antenna to the IMU. You will want to 'Solve lever arm' multiple times. Between each run select the 'Average' and run again. After 3 or 4 times the lever arm will converge and you will know the lever arm. Once the lever arm is determined, you can create a vehicle profile so you wont have to calculate the lever arm again. Now click 'Process' If pre-processing checks pop up, select 'Try to fix the issue(s) before processing' -> Continue Export Wizard Once processing is complete select 'Output' -> 'Export Wizard' Name the exported file and select PCMasterGL in the profile -> Next File name and Location In order for the next processing steps to work smoothly, ensure you place the exported file in the pre-created 'ins' directory and name the file 'ppk.txt'. It should look like this ROCK-XXXX-[DATE]/ins/ppk.txt Select 'Use processing datum' -> Next IMU Epoch Settings -> Finish You will now have a highly refined trajectory file that you can use with PCMasterGL. Step 2 - Create the pointcloud","title":"Process Trajectory"},{"location":"quickstart/checklist/","text":"Flight Checklists \u00b6 Pre-flight \u00b6 Ensure the LiDAR payload is secured to the drone, wifi antenna is attached, and GPS antenna is connected. If using an external battery source for the LiDAR, ensure there is enough voltage for the mission. Ensure there is enough space on the supplied USB stick for the flight. Ensure your base station is logging RINEX data. Power on the LiDAR payload and ensure no errors are being displayed on the status page. Start recording data. Let UAV sit completely still for at least 15 seconds once turned on. Flight \u00b6 Take off and fly quickly in a straight line for 10 seconds. Fly three figure 8 patterns Start the mission Make Sure If your mission will require you to change batteries, then the drone can only be on the ground for a very short period of time (1-2 minutes). Landing \u00b6 Once your mission is complete and you are flying back home, fly two figure 8 patterns before landing. Once landed, don't move the system for 15 seconds. Log in to the LiDAR and stop collecting data.","title":"Flight Checklist"},{"location":"quickstart/checklist/#flight-checklists","text":"","title":"Flight Checklists"},{"location":"quickstart/checklist/#pre-flight","text":"Ensure the LiDAR payload is secured to the drone, wifi antenna is attached, and GPS antenna is connected. If using an external battery source for the LiDAR, ensure there is enough voltage for the mission. Ensure there is enough space on the supplied USB stick for the flight. Ensure your base station is logging RINEX data. Power on the LiDAR payload and ensure no errors are being displayed on the status page. Start recording data. Let UAV sit completely still for at least 15 seconds once turned on.","title":"Pre-flight"},{"location":"quickstart/checklist/#flight","text":"Take off and fly quickly in a straight line for 10 seconds. Fly three figure 8 patterns Start the mission Make Sure If your mission will require you to change batteries, then the drone can only be on the ground for a very short period of time (1-2 minutes).","title":"Flight"},{"location":"quickstart/checklist/#landing","text":"Once your mission is complete and you are flying back home, fly two figure 8 patterns before landing. Once landed, don't move the system for 15 seconds. Log in to the LiDAR and stop collecting data.","title":"Landing"},{"location":"quickstart/first-setup/","text":"First Setup \u00b6 Intro \u00b6 In this tutorial, we will walk you through the following steps: Attach the R1a to your vehicle Power on and connect to the R1a Configure the R1a Setup your base station Calibrate the R1a Collect data Retrieve data for processing To do this, you will need Rock R1a itself, a smartphone or PC, and the vehicle. Attach the R1a to your vehicle \u00b6 The R1a can be attached to any number of vehicles in order to acquire LiDAR data. In this quickstart we will assume you are attaching the LiDAR to a drone. If you are attaching to another vehicle please refer to our Community for additional help. Refer to the setup guide for your particular drone to connect the R1a. DJI Matrice 300 RTK DJI Matrice 210 DJI Matrice 600 Freefly Alta-X Other Drone System Power on and Connecting to the R1a \u00b6 Make Sure Be sure to use the supplied usb drive. Only specific usb drive specifications will work. First, ensure the supplied usb drive is inserted into the R1a. Then, power on the R1a. After powering up the unit, open Wi-Fi settings on your host computer (tablet, smartphone, or PC) and look for the wireless network labeled: ROCKrobotic-###### Connect to this network using the following password: LidarAndINS Next, open up the web browser of your choice and go to the following web address: 192.168.12.1 Configure the R1a \u00b6 In order to obtain as accurate as possible LiDAR data from the R1a, the unit needs to be configured for the data acquisition vehicle. This includes the \"IMU to Antenna Offset\" and the \"Vehicle to IMU Rotation\". If using one of the provided setup kits, the information will be provided for you. If you are using another acquisition vehicle refer to the Community for additional help. Setup your Base Station \u00b6 A highly accurate trajectory is necessary for accurate results from the R1a. In order to obtain this accurate trajectory you must use a GNSS base station. We recommend the Emlid Reach RS2 . Follow the RS2 documentation for setting up your base station. The base station should be configured to log Raw data in RINEX 3.03+ format for the entire duration of the R1a data acquisition. Calibrate the R1a \u00b6 See the complete steps for taking off, calibrating, flying your mission, and landing. Collect Data \u00b6 When you are ready to start collecting data click the 'Start' button within the web interface. The LiDAR, IMU, and GPS will all start collecting data. Proceed with your planned mission! Note: To protect the user from accidently attempting to record data while the USB is unattached, the user does not have the ability to \u201cStart\u201d data recording in the \u201cStatus\u201d window when the USB is unattached. When unattached the user will see the message shown below in Fig. 2-8. Message displayed when trying to record data while USB is unattached. At the completion of the mission you will need to fly three additional figure 8 patterns with the drone and then land. Once on the ground let the drone sit for five minutes before stopping the data collection and powering off the unit. Congratulations! You collected your first LiDAR data! Retrieve Data for Processing \u00b6 All of the LiDAR, IMU, and GPS data is written to the usb stick which is attached to the R1a. When the unit is powered off you can detach the usb and insert into your PC to begin your processing.","title":"First Setup"},{"location":"quickstart/first-setup/#first-setup","text":"","title":"First Setup"},{"location":"quickstart/first-setup/#intro","text":"In this tutorial, we will walk you through the following steps: Attach the R1a to your vehicle Power on and connect to the R1a Configure the R1a Setup your base station Calibrate the R1a Collect data Retrieve data for processing To do this, you will need Rock R1a itself, a smartphone or PC, and the vehicle.","title":"Intro"},{"location":"quickstart/first-setup/#attach-the-r1a-to-your-vehicle","text":"The R1a can be attached to any number of vehicles in order to acquire LiDAR data. In this quickstart we will assume you are attaching the LiDAR to a drone. If you are attaching to another vehicle please refer to our Community for additional help. Refer to the setup guide for your particular drone to connect the R1a. DJI Matrice 300 RTK DJI Matrice 210 DJI Matrice 600 Freefly Alta-X Other Drone System","title":"Attach the R1a to your vehicle"},{"location":"quickstart/first-setup/#power-on-and-connecting-to-the-r1a","text":"Make Sure Be sure to use the supplied usb drive. Only specific usb drive specifications will work. First, ensure the supplied usb drive is inserted into the R1a. Then, power on the R1a. After powering up the unit, open Wi-Fi settings on your host computer (tablet, smartphone, or PC) and look for the wireless network labeled: ROCKrobotic-###### Connect to this network using the following password: LidarAndINS Next, open up the web browser of your choice and go to the following web address: 192.168.12.1","title":"Power on and Connecting to the R1a"},{"location":"quickstart/first-setup/#configure-the-r1a","text":"In order to obtain as accurate as possible LiDAR data from the R1a, the unit needs to be configured for the data acquisition vehicle. This includes the \"IMU to Antenna Offset\" and the \"Vehicle to IMU Rotation\". If using one of the provided setup kits, the information will be provided for you. If you are using another acquisition vehicle refer to the Community for additional help.","title":"Configure the R1a"},{"location":"quickstart/first-setup/#setup-your-base-station","text":"A highly accurate trajectory is necessary for accurate results from the R1a. In order to obtain this accurate trajectory you must use a GNSS base station. We recommend the Emlid Reach RS2 . Follow the RS2 documentation for setting up your base station. The base station should be configured to log Raw data in RINEX 3.03+ format for the entire duration of the R1a data acquisition.","title":"Setup your Base Station"},{"location":"quickstart/first-setup/#calibrate-the-r1a","text":"See the complete steps for taking off, calibrating, flying your mission, and landing.","title":"Calibrate the R1a"},{"location":"quickstart/first-setup/#collect-data","text":"When you are ready to start collecting data click the 'Start' button within the web interface. The LiDAR, IMU, and GPS will all start collecting data. Proceed with your planned mission! Note: To protect the user from accidently attempting to record data while the USB is unattached, the user does not have the ability to \u201cStart\u201d data recording in the \u201cStatus\u201d window when the USB is unattached. When unattached the user will see the message shown below in Fig. 2-8. Message displayed when trying to record data while USB is unattached. At the completion of the mission you will need to fly three additional figure 8 patterns with the drone and then land. Once on the ground let the drone sit for five minutes before stopping the data collection and powering off the unit. Congratulations! You collected your first LiDAR data!","title":"Collect Data"},{"location":"quickstart/first-setup/#retrieve-data-for-processing","text":"All of the LiDAR, IMU, and GPS data is written to the usb stick which is attached to the R1a. When the unit is powered off you can detach the usb and insert into your PC to begin your processing.","title":"Retrieve Data for Processing"},{"location":"quickstart/web-interface/","text":"Navigating the Web Interface \u00b6 The navigation bar has three main menu options. \u201cStatus\u201d, \u201cStorage\u201d and \u201cSettings\u201d. This section will discuss each menu window. Status Menu Window \u00b6 Beginning at the top, the \u201cStatus\u201d option shows the current status of the R1a. Below the \u201cStatus\u201d option is the \u201cData recording\u201d option. The user can toggle between Start and Stop. Storage Menu Window \u00b6 The Storage Menu Window shows the contents of the USB storage device when it is connected to the R1a and the user has clicked \u201cRe-attach\u201d. At this time the user will have the ability to access, download, and view stored files on the USB memory stick. The storage indicator at the top of the screen will be green if storage space is within normal range. It will turn yellow when storage is at 75% max capacity, and turn red when it is at 95% max capacity. You can download or erase data files by clicking on the download or trash icons. Note: It is recommended to remove the USB drive from R1a and plug it into the host computer instead of downloading files over Wi-Fi. This method is much faster because scan files are usually quite large. Settings Menu Window \u00b6 To increase point cloud accuracy and configure specific settings for the LiDAR, use options from the Settings Menu Window. These settings are explained in more detail in the geometry settings section. Connectivity Tab Window \u00b6 The \u201cConnectivity\u201d tab has two sections: \u201cWireless Network\u201d and \u201cRTCM Corrections\u201d. In the \u201cWireless Network\u201d settings the user can configure the R1a to connect to an external WiFi network (only WPA/WPA2 Personal networks are currently supported). If the network is not configured or not in range, the R1a will broadcast its own unique WiFi network, so you can always connect to it. Firmware Tab Window \u00b6 Rock Robotic may occasionally provide a firmware update for the R1a. Refer to the Firmware Update page for more information.","title":"Web Interface"},{"location":"quickstart/web-interface/#navigating-the-web-interface","text":"The navigation bar has three main menu options. \u201cStatus\u201d, \u201cStorage\u201d and \u201cSettings\u201d. This section will discuss each menu window.","title":"Navigating the Web Interface"},{"location":"quickstart/web-interface/#status-menu-window","text":"Beginning at the top, the \u201cStatus\u201d option shows the current status of the R1a. Below the \u201cStatus\u201d option is the \u201cData recording\u201d option. The user can toggle between Start and Stop.","title":"Status Menu Window"},{"location":"quickstart/web-interface/#storage-menu-window","text":"The Storage Menu Window shows the contents of the USB storage device when it is connected to the R1a and the user has clicked \u201cRe-attach\u201d. At this time the user will have the ability to access, download, and view stored files on the USB memory stick. The storage indicator at the top of the screen will be green if storage space is within normal range. It will turn yellow when storage is at 75% max capacity, and turn red when it is at 95% max capacity. You can download or erase data files by clicking on the download or trash icons. Note: It is recommended to remove the USB drive from R1a and plug it into the host computer instead of downloading files over Wi-Fi. This method is much faster because scan files are usually quite large.","title":"Storage Menu Window"},{"location":"quickstart/web-interface/#settings-menu-window","text":"To increase point cloud accuracy and configure specific settings for the LiDAR, use options from the Settings Menu Window. These settings are explained in more detail in the geometry settings section.","title":"Settings Menu Window"},{"location":"quickstart/web-interface/#connectivity-tab-window","text":"The \u201cConnectivity\u201d tab has two sections: \u201cWireless Network\u201d and \u201cRTCM Corrections\u201d. In the \u201cWireless Network\u201d settings the user can configure the R1a to connect to an external WiFi network (only WPA/WPA2 Personal networks are currently supported). If the network is not configured or not in range, the R1a will broadcast its own unique WiFi network, so you can always connect to it.","title":"Connectivity Tab Window"},{"location":"quickstart/web-interface/#firmware-tab-window","text":"Rock Robotic may occasionally provide a firmware update for the R1a. Refer to the Firmware Update page for more information.","title":"Firmware Tab Window"},{"location":"rock-cloud/deliverables/","text":"Deliverables \u00b6 Depending on the selections made during the processing step your data deliverables will change. However, all data processed will result in a 3D pointcloud which can be viewed and analyzed in our Rock Cloud Data Visualizer. Data Visualizer \u00b6 The Rock Cloud has a powerful data visualizer built right in. There are hundreds of different ways to view and analyze your data using our data visualizer. Below are just a few of the most popular. Elevation and Intensity View \u00b6 Open the Rock Visualizer Menu and click Scene --> Select 'Project' in the object tree --> Change the 'Attribute' selection to 'elevation' or 'intensity'. Display Ground Only \u00b6 Open the Rock Visualizer Menu and click 'Filters' --> Select only 'ground' classification. Height Profile \u00b6 Open the Rock Visualizer Menu and click 'Tools' --> Select the 'Height Profile' icon . --> Click once on your point cloud to select the starting point for the height profile, click again for the ending point, then right click to finish the selection process. In the Rock Visualizer Menu select 'Scene' --> Select the 'Profile' in the Objects tree --> Click 'show 2d profile' button. Then you will be presented with the Height Profile Viewer. The height profile units is meters. Annotate \u00b6 The Project owner is able to place annotations on the point cloud and set the default view for the point cloud. Open the Rock Visualizer Menu and click 'Tools' --> Select the Annotation icon . Once selected you can click on the point cloud to place the annotation pin. Scroll down in the sidebar to change the properties of the title and description. To save the annotations and the default camera view, select the 'Set Defaults' link in the sidebar.","title":"Deliverables"},{"location":"rock-cloud/deliverables/#deliverables","text":"Depending on the selections made during the processing step your data deliverables will change. However, all data processed will result in a 3D pointcloud which can be viewed and analyzed in our Rock Cloud Data Visualizer.","title":"Deliverables"},{"location":"rock-cloud/deliverables/#data-visualizer","text":"The Rock Cloud has a powerful data visualizer built right in. There are hundreds of different ways to view and analyze your data using our data visualizer. Below are just a few of the most popular.","title":"Data Visualizer"},{"location":"rock-cloud/deliverables/#elevation-and-intensity-view","text":"Open the Rock Visualizer Menu and click Scene --> Select 'Project' in the object tree --> Change the 'Attribute' selection to 'elevation' or 'intensity'.","title":"Elevation and Intensity View"},{"location":"rock-cloud/deliverables/#display-ground-only","text":"Open the Rock Visualizer Menu and click 'Filters' --> Select only 'ground' classification.","title":"Display Ground Only"},{"location":"rock-cloud/deliverables/#height-profile","text":"Open the Rock Visualizer Menu and click 'Tools' --> Select the 'Height Profile' icon . --> Click once on your point cloud to select the starting point for the height profile, click again for the ending point, then right click to finish the selection process. In the Rock Visualizer Menu select 'Scene' --> Select the 'Profile' in the Objects tree --> Click 'show 2d profile' button. Then you will be presented with the Height Profile Viewer. The height profile units is meters.","title":"Height Profile"},{"location":"rock-cloud/deliverables/#annotate","text":"The Project owner is able to place annotations on the point cloud and set the default view for the point cloud. Open the Rock Visualizer Menu and click 'Tools' --> Select the Annotation icon . Once selected you can click on the point cloud to place the annotation pin. Scroll down in the sidebar to change the properties of the title and description. To save the annotations and the default camera view, select the 'Set Defaults' link in the sidebar.","title":"Annotate"},{"location":"rock-cloud/exporting-in-other-projection-systems/","text":"Exporting in Other Projection Systems \u00b6 Sites and surveys are often in a specific local or custom coordinate system to make measurements more accurate and comply with standards set for the sites. The ROCK Cloud allows users to import, view, and export their data using a custom coordinate system based on EPSG codes, or custom GCPs. Local Projections \u00b6 In addition to common global coordinate systems such as WGS-84 (EPSG 4326) and Web-Mercator (EPSG 3857), there are hundreds of other projections describing local coordinate systems you can export data in. To find out the correct EPSG code for your project follow these steps: Find your EPSG Code EPSG codes are unique identifiers describing the desired projection. The EPSG code for almost any projection can be found on the Spatial Reference Organization's website . Custom Coordinate Systems \u00b6 The ROCK Cloud also allows you to specify your own coordinate system. This is useful for site-specific reference systems based on a location unique to your site. This is done by: Selecting 'Custom Site Projection' in the 'Desired Data Projection' field, and Creating three or more Ground Control Points where the GCP specifies the point in a well known projection using an EPSG code and then specifies the equivalent coordinate in the local custom projection. The ROCK cloud will use this information to create a 4x4 transformational matrix to transform your data. The re-projection pipeline looks like this: LiDAR Data Projection (uploaded projection) --> GCP Projection --> Custom 4x4 transformational matrix Projection","title":"Custom Site Projections"},{"location":"rock-cloud/exporting-in-other-projection-systems/#exporting-in-other-projection-systems","text":"Sites and surveys are often in a specific local or custom coordinate system to make measurements more accurate and comply with standards set for the sites. The ROCK Cloud allows users to import, view, and export their data using a custom coordinate system based on EPSG codes, or custom GCPs.","title":"Exporting in Other Projection Systems"},{"location":"rock-cloud/exporting-in-other-projection-systems/#local-projections","text":"In addition to common global coordinate systems such as WGS-84 (EPSG 4326) and Web-Mercator (EPSG 3857), there are hundreds of other projections describing local coordinate systems you can export data in. To find out the correct EPSG code for your project follow these steps: Find your EPSG Code EPSG codes are unique identifiers describing the desired projection. The EPSG code for almost any projection can be found on the Spatial Reference Organization's website .","title":"Local Projections"},{"location":"rock-cloud/exporting-in-other-projection-systems/#custom-coordinate-systems","text":"The ROCK Cloud also allows you to specify your own coordinate system. This is useful for site-specific reference systems based on a location unique to your site. This is done by: Selecting 'Custom Site Projection' in the 'Desired Data Projection' field, and Creating three or more Ground Control Points where the GCP specifies the point in a well known projection using an EPSG code and then specifies the equivalent coordinate in the local custom projection. The ROCK cloud will use this information to create a 4x4 transformational matrix to transform your data. The re-projection pipeline looks like this: LiDAR Data Projection (uploaded projection) --> GCP Projection --> Custom 4x4 transformational matrix Projection","title":"Custom Coordinate Systems"},{"location":"rock-cloud/getting-started/","text":"Rock Robotic cloud \u00b6 The Rock Robotic Cloud is an all-in-one LiDAR cloud hosting and processing solution. We did the hard work so you can can easily acquire your LiDAR data with the Rock Robotic R1a, upload to our secure servers , and see results. Create a free Rock Robotic Cloud account today so see some demo datasets. Create account \u00b6 Upon navigating to https://cloud.rockrobotic.com you will be asked to create an account secured by two-factor authentication. Demo Projects \u00b6 Once logged in you will have access to a number of demo projects. Each of these demo projects give you the experience of the Rock Robotic Cloud Platform. Learn more about the Creating your first Project .","title":"Getting Started"},{"location":"rock-cloud/getting-started/#rock-robotic-cloud","text":"The Rock Robotic Cloud is an all-in-one LiDAR cloud hosting and processing solution. We did the hard work so you can can easily acquire your LiDAR data with the Rock Robotic R1a, upload to our secure servers , and see results. Create a free Rock Robotic Cloud account today so see some demo datasets.","title":"Rock Robotic cloud"},{"location":"rock-cloud/getting-started/#create-account","text":"Upon navigating to https://cloud.rockrobotic.com you will be asked to create an account secured by two-factor authentication.","title":"Create account"},{"location":"rock-cloud/getting-started/#demo-projects","text":"Once logged in you will have access to a number of demo projects. Each of these demo projects give you the experience of the Rock Robotic Cloud Platform. Learn more about the Creating your first Project .","title":"Demo Projects"},{"location":"rock-cloud/process/","text":"Process \u00b6 Once your project is created and your data is uploaded, you are now ready to submit your project for processing. Simply click the 'Process' button and you are on your way. Process \u00b6 Click the Process link at the top of you project, select the deliverables you would like and you will be notified once the processing is complete. Point Cloud \u00b6 COMING SOON: You can select to manipulate your point cloud in the cloud. This includes re-projecting, moving, etc... DEM and Contours \u00b6 Processing your data into a Digital Elevation Model and Contour file gives you several deliverables. 3D Ground Classified Point cloud (.las format) Digital Elevation Model (.tif format) Contour files (.shx, .dbf, .shp formats) Tokens \u00b6 The Rock Robotic Cloud uses a token system for cloud processing. The number of tokens for a particular deliverable is determined by the deliverable type and the amount of LiDAR data to be processed. To give you an idea of scale, the Airport Runway dataset is approximately .125 square kilometers and would cost 0 tokens to receive a 3D point cloud and 2 tokens to receive a DEM and contours. Let's look at the data!","title":"Process"},{"location":"rock-cloud/process/#process","text":"Once your project is created and your data is uploaded, you are now ready to submit your project for processing. Simply click the 'Process' button and you are on your way.","title":"Process"},{"location":"rock-cloud/process/#process_1","text":"Click the Process link at the top of you project, select the deliverables you would like and you will be notified once the processing is complete.","title":"Process"},{"location":"rock-cloud/process/#point-cloud","text":"COMING SOON: You can select to manipulate your point cloud in the cloud. This includes re-projecting, moving, etc...","title":"Point Cloud"},{"location":"rock-cloud/process/#dem-and-contours","text":"Processing your data into a Digital Elevation Model and Contour file gives you several deliverables. 3D Ground Classified Point cloud (.las format) Digital Elevation Model (.tif format) Contour files (.shx, .dbf, .shp formats)","title":"DEM and Contours"},{"location":"rock-cloud/process/#tokens","text":"The Rock Robotic Cloud uses a token system for cloud processing. The number of tokens for a particular deliverable is determined by the deliverable type and the amount of LiDAR data to be processed. To give you an idea of scale, the Airport Runway dataset is approximately .125 square kilometers and would cost 0 tokens to receive a 3D point cloud and 2 tokens to receive a DEM and contours. Let's look at the data!","title":"Tokens"},{"location":"rock-cloud/project/","text":"Projects \u00b6 Creating a project allows you to upload all of your LiDAR data and submit for processing. Add New Project \u00b6 Simply click 'Add New Project' And you will be presented with an easy and intuitive interface to upload your data. Project data \u00b6 The two major file types that the ROCK Cloud suppors is .las and .laz. LAZ files are compressed and lossless LAS files. The compression of these files can be extraordinary. We recommend that all .las files be converted to .laz files prior to upload. If converted prior to upload, there will be a substantial savings in upload time and cloud storage space used. Visit laszip.org to download the command-line version 'laszip-cli.exe' or the GUI version 'laszip.exe'. Ground Control Points \u00b6 If you have a Pro plan you will have the ability to add one or more ground control points to your project. These ground control points will be used to improve the global accuracy of your LiDAR deliverables and they will be visible in the Rock Cloud Data Visualizer. Project location \u00b6 The project location will automatically be calculated if the las/laz file uploaded contains the appropriate header information or if the correct projection information is specified on the project page. However, you can manually update the project location if the location cannot be found. Save the Project \u00b6 Once complete, save your project and your data will be queued up for processing. Processing typically takes from 1-5 minutes to process. Once you see the LIDAR button, you know your project is ready to view. Time to process your data!","title":"Project"},{"location":"rock-cloud/project/#projects","text":"Creating a project allows you to upload all of your LiDAR data and submit for processing.","title":"Projects"},{"location":"rock-cloud/project/#add-new-project","text":"Simply click 'Add New Project' And you will be presented with an easy and intuitive interface to upload your data.","title":"Add New Project"},{"location":"rock-cloud/project/#project-data","text":"The two major file types that the ROCK Cloud suppors is .las and .laz. LAZ files are compressed and lossless LAS files. The compression of these files can be extraordinary. We recommend that all .las files be converted to .laz files prior to upload. If converted prior to upload, there will be a substantial savings in upload time and cloud storage space used. Visit laszip.org to download the command-line version 'laszip-cli.exe' or the GUI version 'laszip.exe'.","title":"Project data"},{"location":"rock-cloud/project/#ground-control-points","text":"If you have a Pro plan you will have the ability to add one or more ground control points to your project. These ground control points will be used to improve the global accuracy of your LiDAR deliverables and they will be visible in the Rock Cloud Data Visualizer.","title":"Ground Control Points"},{"location":"rock-cloud/project/#project-location","text":"The project location will automatically be calculated if the las/laz file uploaded contains the appropriate header information or if the correct projection information is specified on the project page. However, you can manually update the project location if the location cannot be found.","title":"Project location"},{"location":"rock-cloud/project/#save-the-project","text":"Once complete, save your project and your data will be queued up for processing. Processing typically takes from 1-5 minutes to process. Once you see the LIDAR button, you know your project is ready to view. Time to process your data!","title":"Save the Project"},{"location":"rock-cloud/webgl/","text":"WebGL 2.0 \u00b6 WebGL 2.0 is needed to view the LiDAR data online. Some browsers do not have support for WebGL 2.0. If you are unable to view the LiDAR data online then first update your browser to the latest Chrome or Firefox. If you continue to have issues, then you may need to enable WebGL support. Firefox \u00b6 Go to about:config Search for webgl2 Double click on webgl.enable-prototype-webgl2 until the value is true Restart Firefox Chrome \u00b6 Go to chrome://flags Search for webgl Enable WebGL support Restart Chrome","title":"WebGL"},{"location":"rock-cloud/webgl/#webgl-20","text":"WebGL 2.0 is needed to view the LiDAR data online. Some browsers do not have support for WebGL 2.0. If you are unable to view the LiDAR data online then first update your browser to the latest Chrome or Firefox. If you continue to have issues, then you may need to enable WebGL support.","title":"WebGL 2.0"},{"location":"rock-cloud/webgl/#firefox","text":"Go to about:config Search for webgl2 Double click on webgl.enable-prototype-webgl2 until the value is true Restart Firefox","title":"Firefox"},{"location":"rock-cloud/webgl/#chrome","text":"Go to chrome://flags Search for webgl Enable WebGL support Restart Chrome","title":"Chrome"},{"location":"tutorials/Placing-the-Base/","text":"Placing the Base Station \u00b6 Measuring Base Height Overview \u00b6 LiDAR data acquisition requires 2 receivers. One of them is stationary and is called \u201cbase station\u201d, the other one, on the ROCK R1A, is the \u201crover\u201d. The base station measures errors, and knowing that it is stationary transmits corrections to the rover (refer to How RTK and PPK works for more information about RTK and PPK). Typically the distance between the Base and the R1A rover shouldn't exceed 10 km due to the ionospheric effect. A general rule of thumb is, you will lose 2 parts in accuracy per million. (i.e. at 10 km you will lose 2 cm of accuracy) Because of this we recommend to always have a base station located within 10 km of your project area. This article will give you a good understanding of different ways to set up the base to help you attain the desired accuracy for your application. In this tutorial we will show discuss 3 scenarios for setting up your base. Setting up over known Point (High Global Accuracy) Setting up over unknown (Post-Processing Position, High Global Accuracy) Setting up over unknown (relative accuracy) Absolute and relative position \u00b6 ROCK cloud has several ways to determine your position with varying levels of accuracy. Let's take a look at the illustration below (figure 1). The ROCK Cloud algorithm can precisely calculates the distance between the base and R1A rover. This distance is called the Baseline. The R1A rover position is precisely determined relative to the Base position. The more precisely we can locate our base station then the more accurate our location for the rover will be, and as a result, the accuracy for our LiDAR data. Any offset from the true location on the base station from the true location will be directly applied to the rover coordinates offset, and by extension to our LiDAR data. Figure 1 It is often enough to know the precise position of an object relative to other objects inside the scan area. This would preserve measurements made on the LiDAR model, but lose where these measurements are located on earth. However, for applications like surveying and mapping it is critical to get an accurate absolute position for your base station. In this case, the offset \u0394X, \u0394Y, \u0394Z between actual True position and the Base station position should be avoided or reduced. The absolute position of the rover and therefore the LiDAR data is accurate only to the same accuracy as the position of the base station. In the below figure 2 is an illustration showing the effects of the base station location being off from the true location. As you can see, if the base station computed location is off from the true position, then the R1A rover and likewise the LiDAR data is shifted by the same amount. Next, we will discuss 3 methods of locating your base station to be uploaded to the ROCK cloud. Figure 2 Ways to Set the Base Station \u00b6 Setting over a Known Point Setting over an unknown point with post processing position (PPP) Unknown point, don't care :) Setting Up Base Over a Known Point \u00b6 It is often the case that you will arrive on a job site that has already been surveyed and there exists a survey benchmark on this job site. Figure 3 depicts several examples of common job site survey benchmarks/markers/monuments. Figure 3 This is the best case scenario. In this procedure, you will place your base station directly over the center point of the survey marker. After the base station is secured and leveled above the marker, then you will take an accurate measurement of your base station height. See Measuring Base Height for a detailed explanation of measuring the base height. Pay Attention! The mismeasured height of the antenna above the mark is probably the most pervasive and frequent blunder in GPS control surveying. Measuring Base height \u00b6","title":"Placing the Base"},{"location":"tutorials/Placing-the-Base/#placing-the-base-station","text":"Measuring Base Height","title":"Placing the Base Station"},{"location":"tutorials/Placing-the-Base/#overview","text":"LiDAR data acquisition requires 2 receivers. One of them is stationary and is called \u201cbase station\u201d, the other one, on the ROCK R1A, is the \u201crover\u201d. The base station measures errors, and knowing that it is stationary transmits corrections to the rover (refer to How RTK and PPK works for more information about RTK and PPK). Typically the distance between the Base and the R1A rover shouldn't exceed 10 km due to the ionospheric effect. A general rule of thumb is, you will lose 2 parts in accuracy per million. (i.e. at 10 km you will lose 2 cm of accuracy) Because of this we recommend to always have a base station located within 10 km of your project area. This article will give you a good understanding of different ways to set up the base to help you attain the desired accuracy for your application. In this tutorial we will show discuss 3 scenarios for setting up your base. Setting up over known Point (High Global Accuracy) Setting up over unknown (Post-Processing Position, High Global Accuracy) Setting up over unknown (relative accuracy)","title":"Overview"},{"location":"tutorials/Placing-the-Base/#absolute-and-relative-position","text":"ROCK cloud has several ways to determine your position with varying levels of accuracy. Let's take a look at the illustration below (figure 1). The ROCK Cloud algorithm can precisely calculates the distance between the base and R1A rover. This distance is called the Baseline. The R1A rover position is precisely determined relative to the Base position. The more precisely we can locate our base station then the more accurate our location for the rover will be, and as a result, the accuracy for our LiDAR data. Any offset from the true location on the base station from the true location will be directly applied to the rover coordinates offset, and by extension to our LiDAR data. Figure 1 It is often enough to know the precise position of an object relative to other objects inside the scan area. This would preserve measurements made on the LiDAR model, but lose where these measurements are located on earth. However, for applications like surveying and mapping it is critical to get an accurate absolute position for your base station. In this case, the offset \u0394X, \u0394Y, \u0394Z between actual True position and the Base station position should be avoided or reduced. The absolute position of the rover and therefore the LiDAR data is accurate only to the same accuracy as the position of the base station. In the below figure 2 is an illustration showing the effects of the base station location being off from the true location. As you can see, if the base station computed location is off from the true position, then the R1A rover and likewise the LiDAR data is shifted by the same amount. Next, we will discuss 3 methods of locating your base station to be uploaded to the ROCK cloud. Figure 2","title":"Absolute and relative position"},{"location":"tutorials/Placing-the-Base/#ways-to-set-the-base-station","text":"Setting over a Known Point Setting over an unknown point with post processing position (PPP) Unknown point, don't care :)","title":"Ways to Set the Base Station"},{"location":"tutorials/Placing-the-Base/#setting-up-base-over-a-known-point","text":"It is often the case that you will arrive on a job site that has already been surveyed and there exists a survey benchmark on this job site. Figure 3 depicts several examples of common job site survey benchmarks/markers/monuments. Figure 3 This is the best case scenario. In this procedure, you will place your base station directly over the center point of the survey marker. After the base station is secured and leveled above the marker, then you will take an accurate measurement of your base station height. See Measuring Base Height for a detailed explanation of measuring the base height. Pay Attention! The mismeasured height of the antenna above the mark is probably the most pervasive and frequent blunder in GPS control surveying.","title":"Setting Up Base Over a Known Point"},{"location":"tutorials/Placing-the-Base/#measuring-base-height","text":"","title":"Measuring Base height"},{"location":"tutorials/Terrain-Following-Tutorial/","text":"Terrain Following \u00b6 Documentation in progress. Check back soon.","title":"Terrain Following"},{"location":"tutorials/Terrain-Following-Tutorial/#terrain-following","text":"Documentation in progress. Check back soon.","title":"Terrain Following"},{"location":"tutorials/advanced-mission/","text":"Advanced Mission Planning \u00b6 In this section we will provide recommendation for mission planning software. These are 3rd party software and are only from our experience and recommendations. With all mission planning software a certain level of risk exists and you as a pilot must remain aware at all times. Recommended Flight Control Software \u00b6","title":"Advanced Mission Planning"},{"location":"tutorials/advanced-mission/#advanced-mission-planning","text":"In this section we will provide recommendation for mission planning software. These are 3rd party software and are only from our experience and recommendations. With all mission planning software a certain level of risk exists and you as a pilot must remain aware at all times.","title":"Advanced Mission Planning"},{"location":"tutorials/advanced-mission/#recommended-flight-control-software","text":"","title":"Recommended Flight Control Software"},{"location":"tutorials/connectivity/","text":"Connectivity \u00b6 External WiFi networks can be useful for supplying differential GNSS corrections to the R1a for RTK trajectory generation. In the options for \u201cRTCM Corrections\u201d the user can choose the delivery method for corrections to the R1a. The options are: * USB RF Modem like Holybro 915MHz * NTRIP Client * TCP Server the R1a connects to * TCP Client connecting to the R1a\u2019s pre-defined port Click \u201cSave\u201d to save the changes. The R1a will immediately start trying to connect to the selected channel. * If \u201cTCP Listen\u201d is selected, the R1a will always listen on the port, and once a client connects to the port, the R1a will accept the connection. * If \u201cUSB RF Modem\u201d is selected, the R1a will automatically detect connection of a compatible USB RF Modem and open the serial link. * If \u201cNTRIP Client\u201d or \u201cTCP Connect\u201d is selected, the R1a will keep trying to connect to the specified address until it succeeds. Once a connection is established, the R1a will start sending its position in a NMEA0183 $GPGGA message, so a virtual reference station can be generated. Real base stations ignore those messages. Once the R1a receives RTCMv3 corrections, it will use them to compute RTK position. It will also record the RTCMv3 messages it has received while recording data, so they can be used for post-processing as well. Click \u201cRestore\u201d to discard any unsaved changes.","title":"Connectivity"},{"location":"tutorials/connectivity/#connectivity","text":"External WiFi networks can be useful for supplying differential GNSS corrections to the R1a for RTK trajectory generation. In the options for \u201cRTCM Corrections\u201d the user can choose the delivery method for corrections to the R1a. The options are: * USB RF Modem like Holybro 915MHz * NTRIP Client * TCP Server the R1a connects to * TCP Client connecting to the R1a\u2019s pre-defined port Click \u201cSave\u201d to save the changes. The R1a will immediately start trying to connect to the selected channel. * If \u201cTCP Listen\u201d is selected, the R1a will always listen on the port, and once a client connects to the port, the R1a will accept the connection. * If \u201cUSB RF Modem\u201d is selected, the R1a will automatically detect connection of a compatible USB RF Modem and open the serial link. * If \u201cNTRIP Client\u201d or \u201cTCP Connect\u201d is selected, the R1a will keep trying to connect to the specified address until it succeeds. Once a connection is established, the R1a will start sending its position in a NMEA0183 $GPGGA message, so a virtual reference station can be generated. Real base stations ignore those messages. Once the R1a receives RTCMv3 corrections, it will use them to compute RTK position. It will also record the RTCMv3 messages it has received while recording data, so they can be used for post-processing as well. Click \u201cRestore\u201d to discard any unsaved changes.","title":"Connectivity"},{"location":"tutorials/firmware/","text":"Firmware Update \u00b6 Rock Robotic may occasionally provide a firmware update for the R1a. When this occurs, load the firmware update file onto the USB drive and connect the drive to the R1a. Inside the \u201cFirmware\u201d tab window under \u201cSettings\u201d you can install firmware updates by clicking on the button labeled \u201cInstall\u201d.","title":"Firmware Update"},{"location":"tutorials/firmware/#firmware-update","text":"Rock Robotic may occasionally provide a firmware update for the R1a. When this occurs, load the firmware update file onto the USB drive and connect the drive to the R1a. Inside the \u201cFirmware\u201d tab window under \u201cSettings\u201d you can install firmware updates by clicking on the button labeled \u201cInstall\u201d.","title":"Firmware Update"},{"location":"tutorials/geometry-configuration/","text":"Geometry Configuration \u00b6 IMU to Antenna Offset \u00b6 In the \u201cIMU to Antenna Offset\u201d option enter the correct location of the antenna relative to the internal IMU using location of IMU center inside R1a for measuring antenna offset. The orientation of the IMU within the R1a is shown below: \"Right\" refers to the \"X\" direction. \"Forward\" refers to the \"Y\" direction. \"Up\" refers to the \"Z\" direction. The precise location of the IMU is depicted below in millimeters. Vehicle to IMU Rotation \u00b6 In the \u201cVehicle to IMU Rotation\u201d option enter in the relative offset angles (axis misalignment; alignment angles) between the R1a and the carrier vehicle. Yaw, Pitch and Roll should all be measured with respect to the axes on the carrier object (i.e. \u2013 the measured Yaw value is measured relative to the front-end of the carrier object). Static Alignment \u00b6 The \u201cStatic Alignment\u201d option should be kept at 5 seconds (recommended) unless the carrier vehicle is unable to remain in a static position for this amount of time. When data-recording is started on the R1a, gyro biases will be estimated and used in data filtering processes.","title":"Geometry Configuration"},{"location":"tutorials/geometry-configuration/#geometry-configuration","text":"","title":"Geometry Configuration"},{"location":"tutorials/geometry-configuration/#imu-to-antenna-offset","text":"In the \u201cIMU to Antenna Offset\u201d option enter the correct location of the antenna relative to the internal IMU using location of IMU center inside R1a for measuring antenna offset. The orientation of the IMU within the R1a is shown below: \"Right\" refers to the \"X\" direction. \"Forward\" refers to the \"Y\" direction. \"Up\" refers to the \"Z\" direction. The precise location of the IMU is depicted below in millimeters.","title":"IMU to Antenna Offset"},{"location":"tutorials/geometry-configuration/#vehicle-to-imu-rotation","text":"In the \u201cVehicle to IMU Rotation\u201d option enter in the relative offset angles (axis misalignment; alignment angles) between the R1a and the carrier vehicle. Yaw, Pitch and Roll should all be measured with respect to the axes on the carrier object (i.e. \u2013 the measured Yaw value is measured relative to the front-end of the carrier object).","title":"Vehicle to IMU Rotation"},{"location":"tutorials/geometry-configuration/#static-alignment","text":"The \u201cStatic Alignment\u201d option should be kept at 5 seconds (recommended) unless the carrier vehicle is unable to remain in a static position for this amount of time. When data-recording is started on the R1a, gyro biases will be estimated and used in data filtering processes.","title":"Static Alignment"},{"location":"tutorials/r1a-boresighting/","text":"R1A Boresighting \u00b6 Remote Sensing Payload Instrument (R1A) \u2013 consists of a LiDAR and an Inertial Navigation System (INS). In order to accurately georeference the point clouds generated by the LiDAR it must be aligned with the Inertial Measurement Unit (IMU) of the INS used to generate georeferenced trajectory. Moreover, each laser in a multi-laser LiDAR, like the Velodyne VLP-16 used in R1A, must be properly aligned. This alignment process is called \"Boresighting\", and is described in this manual. Boresighting is performed based on a scan of an area having a special feature: a tall vertical edge. This edge can be a corner of a building or a tall tower or pole. The scan can be done using a multi-copter drone or a car as the carrier vehicle. Generally, car boresighting is more convenient, but drone boresighting may be preferred if the area used for boresighting is not suited for a car to drive in the necessary pattern during procedure. This document discusses car boresighting. LiDAR boresighting and calibration \u2013 drive pattern \u00b6 Drive Pattern Notes: Red lines are critical \u2013 they need to be performed as specified Blue lines are not critical \u2013 they can be performed anywhere Velocity on the red lines should be \\<5 m/sec Before and after the boresighting pattern, the following convergence maneuvers must be performed to ensure good observability of IMU heading: Straight drive forward, for duration of at least 5 seconds, at least 5 m/sec Left and right turns in motion, at least 90 degrees each Boresighting pattern Left and right turns in motion, at least 90 degrees each Straight drive forward, for duration of at least 5 seconds, at least 5 m/sec LiDAR should be mounted on the vehicle with its axis pitched up about 15 degrees LiDAR laser alignment parameters \u00b6 The Velodyne VLP-16 lasers have the following misalignment angles: Common for all lasers: Yaw offset between IMU and LiDAR Pitch offset between IMU and LiDAR Roll offset between IMU and LiDAR Individual for each laser: Rotation offset (\"Azimuth\") of the laser (zero for one of the lasers used as reference, because this offset is coupled with roll offset between IMU and LiDAR) Conicity offset (\"Elevation\") of the laser (if the laser is perfectly calibrated, then it is the LiDAR reference elevation, zero for laser #1) Each alignment parameter has its own effect on scan line positions for the back and forth scans of the critical area above. Here is the effect of each parameter on laser #1 clouds from East-West scan of the Critical Area when the pitch of the LiDAR axis is 15 degrees. It is assumed that when the alignment parameters are correct, all edges in the critical area match in each of the scans (forward and backward). That means: The IMU-antenna offset is correct. the IMU heading convergence is good. The IMU-LiDAR linear offsets are set correctly. Blue shows the scans when all alignment parameters are correct. Pink shows the scans when the respective alignment parameter is incorrect. Obviously, edge mismatches in Pitch, Roll, and Elevation are very well observable between back and forth scans of the critical area. They can be corrected separately from each other by aligning the appropriate edges in the two clouds. Yaw offset, however, has very poor observability. It just moves the vertical edge horizontally in the same direction in both clouds, for example, forward (West) in the West scan and backward (West again) in the East scan. This is where the North-South scan becomes helpful. If we look at both scans of the critical area from the top after correcting all other alignment parameters, we will see the effect of Yaw immediately. Here, in a zoomed view of the critical area, blue is the East-West scan (both directions), pink is the North-South scan (both directions). The edges from the two sets of clouds can be aligned by adjusting the Yaw offset. So, if all parameters of laser #1 are incorrect, the clouds will look like this (blue is the East scan, pink is the West scan): After adjusting Roll, the clouds will look like this: Now, let's focus on the bottom of the vertical edge for adjusting Elevation. Before: After: And then, the top of the vertical edge for adjusting Pitch. Before: After: One catch is that after adjusting Yaw: We get back to the side view of the East-West scan, and see this in zoomed bottom of the vertical edge: That is because Yaw and Roll are slightly coupled because of LiDAR tilt of 15 degrees. So, the final step is to refine Roll adjustment: This finalizes the LiDAR boresighting and reference laser calibration. Calibrating all lasers \u00b6 Calibration workflow starts with boresighting using one laser. It can be any laser; the only difference is that the laser used for boresighting will have a zero Azimuth offset. All other lasers will have Azimuth offsets relative to the reference laser. The reference laser is selected in PCMaster software, where its Azimuth offset is set to zero, the trajectory parts for both directions of North-South and East-West scans are selected and the boresighting process is done as described above. Then, the Roll is changed and clouds regenerated until top and bottom edges of the building are aligned in the East-West scans. They will also be aligned in the North-South scans. After that, the Elevation is changed to align the vertical edge of the building at the altitude of the LiDAR in the East-West scans. It will also be aligned in the North-South scans. If the vertical edge is not aligned at the top of the building, Pitch is changed until it is aligned. Then the Yaw offset is corrected. For that, the vertical edge from both East-West and North-South scans is aligned. And the last step is refining the Roll offset. After the reference laser is calibrated, it is selected in PCMaster in pair with each of the other lasers. Then, the vertical edges from the two lasers are aligned by changing the other laser's Elevation, and the horizontal edges are aligned by changing the other laser's Azimuth. The reference laser's Azimuth must remain zero . Before (reference laser is blue, the other laser is pink): After: Sensitivity and range \u00b6 This boresighting method uses the fact that linear mismatches caused by angular offsets grow with distance. The rule of thumb is that every milliradian (0.06 degree) of angular offset will produce 2 cm of linear mismatch between the two clouds for every 10 meters of distance to the wall. That means, the wall should be as far from the trajectory as the lidar range allows to reach the top of the wall. Having the wall 40-50 meters away will result in an 8-10 cm mismatch for every milliradian of angular offset. One exception is the Pitch offset. Its observability depends on the height of the building. Every 10 meters of height will produce 2 cm of mismatch at the top for every milliradian of Pitch offset. That means, the building used should be as tall as possible. Scanning with a low velocity allows for the increase of scan line density, which results in a better visibility of edges. It may also be beneficial to decrease the LiDAR scan rate to 300 RPM to increase the angular resolution of the scans. Storing the computed values \u00b6 PCMasterGL, the software that is used for boresighting and laser calibration, saves the computed values in the PCMaster Project file. This file can be loaded onto the R1A device using the R1A Web interface. After that, the values will be recorded in the LiDAR scan files on the R1A device, and when those files are loaded in a newly created PCMaster Project, the values will also be automatically loaded there. In order to store the values, open the R1A Web interface and go to the Settings-\\>Boresight page. Then, click \"Read from PCMaster project\" and browse for the PCMaster Project file. After the file is selected, the computed values will be extracted from the file and stored in the R1A non-volatile memory.","title":"R1A Boresighting"},{"location":"tutorials/r1a-boresighting/#r1a-boresighting","text":"Remote Sensing Payload Instrument (R1A) \u2013 consists of a LiDAR and an Inertial Navigation System (INS). In order to accurately georeference the point clouds generated by the LiDAR it must be aligned with the Inertial Measurement Unit (IMU) of the INS used to generate georeferenced trajectory. Moreover, each laser in a multi-laser LiDAR, like the Velodyne VLP-16 used in R1A, must be properly aligned. This alignment process is called \"Boresighting\", and is described in this manual. Boresighting is performed based on a scan of an area having a special feature: a tall vertical edge. This edge can be a corner of a building or a tall tower or pole. The scan can be done using a multi-copter drone or a car as the carrier vehicle. Generally, car boresighting is more convenient, but drone boresighting may be preferred if the area used for boresighting is not suited for a car to drive in the necessary pattern during procedure. This document discusses car boresighting.","title":"R1A Boresighting"},{"location":"tutorials/r1a-boresighting/#lidar-boresighting-and-calibration-drive-pattern","text":"Drive Pattern Notes: Red lines are critical \u2013 they need to be performed as specified Blue lines are not critical \u2013 they can be performed anywhere Velocity on the red lines should be \\<5 m/sec Before and after the boresighting pattern, the following convergence maneuvers must be performed to ensure good observability of IMU heading: Straight drive forward, for duration of at least 5 seconds, at least 5 m/sec Left and right turns in motion, at least 90 degrees each Boresighting pattern Left and right turns in motion, at least 90 degrees each Straight drive forward, for duration of at least 5 seconds, at least 5 m/sec LiDAR should be mounted on the vehicle with its axis pitched up about 15 degrees","title":"LiDAR boresighting and calibration \u2013 drive pattern"},{"location":"tutorials/r1a-boresighting/#lidar-laser-alignment-parameters","text":"The Velodyne VLP-16 lasers have the following misalignment angles: Common for all lasers: Yaw offset between IMU and LiDAR Pitch offset between IMU and LiDAR Roll offset between IMU and LiDAR Individual for each laser: Rotation offset (\"Azimuth\") of the laser (zero for one of the lasers used as reference, because this offset is coupled with roll offset between IMU and LiDAR) Conicity offset (\"Elevation\") of the laser (if the laser is perfectly calibrated, then it is the LiDAR reference elevation, zero for laser #1) Each alignment parameter has its own effect on scan line positions for the back and forth scans of the critical area above. Here is the effect of each parameter on laser #1 clouds from East-West scan of the Critical Area when the pitch of the LiDAR axis is 15 degrees. It is assumed that when the alignment parameters are correct, all edges in the critical area match in each of the scans (forward and backward). That means: The IMU-antenna offset is correct. the IMU heading convergence is good. The IMU-LiDAR linear offsets are set correctly. Blue shows the scans when all alignment parameters are correct. Pink shows the scans when the respective alignment parameter is incorrect. Obviously, edge mismatches in Pitch, Roll, and Elevation are very well observable between back and forth scans of the critical area. They can be corrected separately from each other by aligning the appropriate edges in the two clouds. Yaw offset, however, has very poor observability. It just moves the vertical edge horizontally in the same direction in both clouds, for example, forward (West) in the West scan and backward (West again) in the East scan. This is where the North-South scan becomes helpful. If we look at both scans of the critical area from the top after correcting all other alignment parameters, we will see the effect of Yaw immediately. Here, in a zoomed view of the critical area, blue is the East-West scan (both directions), pink is the North-South scan (both directions). The edges from the two sets of clouds can be aligned by adjusting the Yaw offset. So, if all parameters of laser #1 are incorrect, the clouds will look like this (blue is the East scan, pink is the West scan): After adjusting Roll, the clouds will look like this: Now, let's focus on the bottom of the vertical edge for adjusting Elevation. Before: After: And then, the top of the vertical edge for adjusting Pitch. Before: After: One catch is that after adjusting Yaw: We get back to the side view of the East-West scan, and see this in zoomed bottom of the vertical edge: That is because Yaw and Roll are slightly coupled because of LiDAR tilt of 15 degrees. So, the final step is to refine Roll adjustment: This finalizes the LiDAR boresighting and reference laser calibration.","title":"LiDAR laser alignment parameters"},{"location":"tutorials/r1a-boresighting/#calibrating-all-lasers","text":"Calibration workflow starts with boresighting using one laser. It can be any laser; the only difference is that the laser used for boresighting will have a zero Azimuth offset. All other lasers will have Azimuth offsets relative to the reference laser. The reference laser is selected in PCMaster software, where its Azimuth offset is set to zero, the trajectory parts for both directions of North-South and East-West scans are selected and the boresighting process is done as described above. Then, the Roll is changed and clouds regenerated until top and bottom edges of the building are aligned in the East-West scans. They will also be aligned in the North-South scans. After that, the Elevation is changed to align the vertical edge of the building at the altitude of the LiDAR in the East-West scans. It will also be aligned in the North-South scans. If the vertical edge is not aligned at the top of the building, Pitch is changed until it is aligned. Then the Yaw offset is corrected. For that, the vertical edge from both East-West and North-South scans is aligned. And the last step is refining the Roll offset. After the reference laser is calibrated, it is selected in PCMaster in pair with each of the other lasers. Then, the vertical edges from the two lasers are aligned by changing the other laser's Elevation, and the horizontal edges are aligned by changing the other laser's Azimuth. The reference laser's Azimuth must remain zero . Before (reference laser is blue, the other laser is pink): After:","title":"Calibrating all lasers"},{"location":"tutorials/r1a-boresighting/#sensitivity-and-range","text":"This boresighting method uses the fact that linear mismatches caused by angular offsets grow with distance. The rule of thumb is that every milliradian (0.06 degree) of angular offset will produce 2 cm of linear mismatch between the two clouds for every 10 meters of distance to the wall. That means, the wall should be as far from the trajectory as the lidar range allows to reach the top of the wall. Having the wall 40-50 meters away will result in an 8-10 cm mismatch for every milliradian of angular offset. One exception is the Pitch offset. Its observability depends on the height of the building. Every 10 meters of height will produce 2 cm of mismatch at the top for every milliradian of Pitch offset. That means, the building used should be as tall as possible. Scanning with a low velocity allows for the increase of scan line density, which results in a better visibility of edges. It may also be beneficial to decrease the LiDAR scan rate to 300 RPM to increase the angular resolution of the scans.","title":"Sensitivity and range"},{"location":"tutorials/r1a-boresighting/#storing-the-computed-values","text":"PCMasterGL, the software that is used for boresighting and laser calibration, saves the computed values in the PCMaster Project file. This file can be loaded onto the R1A device using the R1A Web interface. After that, the values will be recorded in the LiDAR scan files on the R1A device, and when those files are loaded in a newly created PCMaster Project, the values will also be automatically loaded there. In order to store the values, open the R1A Web interface and go to the Settings-\\>Boresight page. Then, click \"Read from PCMaster project\" and browse for the PCMaster Project file. After the file is selected, the computed values will be extracted from the file and stored in the R1A non-volatile memory.","title":"Storing the computed values"},{"location":"tutorials/usb/","text":"USB Drive \u00b6 Make Sure Be sure to use the supplied usb drive. Only specific usb drive specifications will work. Additional usb drives can be purchased from Amazon . Prepare USB drive \u00b6 The usb drive must be formatted as FAT32 . FAT32Format GUI - Windows Use Quick format with an allocation size of 32K.","title":"USB Drive"},{"location":"tutorials/usb/#usb-drive","text":"Make Sure Be sure to use the supplied usb drive. Only specific usb drive specifications will work. Additional usb drives can be purchased from Amazon .","title":"USB Drive"},{"location":"tutorials/usb/#prepare-usb-drive","text":"The usb drive must be formatted as FAT32 . FAT32Format GUI - Windows Use Quick format with an allocation size of 32K.","title":"Prepare USB drive"}]}